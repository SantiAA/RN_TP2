{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436d9281-193b-451f-ada0-21a7c5abcb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from os.path import join\n",
    "from os import getcwd\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9677c95-49b9-4f82-9283-56f2a4cb0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef186b77-73a2-477f-b75b-f892d14573f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.metrics import AUC # Area under the curve, default: ROC\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.initializers import GlorotNormal\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053b97da-bbb4-4991-9f03-51c49a1e0a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275ff8f8-db58-42f5-b706-0a99a4084360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoints_path = getcwd()+'\\\\checkpoints_A'\n",
    "tensor_path = getcwd()+'\\\\tensor_A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90e9f7f9-24f9-4285-9f84-c52c0bec026b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../databases/diabetes.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7edbf194-e5b0-442b-ad5f-e2716ec4301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlayers = {\n",
    "    'BloodPressure': (40, np.Inf),\n",
    "    'SkinThickness': (0, 80),\n",
    "    'Insulin': (0, 400),\n",
    "    'BMI': (0, 50)\n",
    "}\n",
    "\n",
    "zeros = [\n",
    "    'Glucose',\n",
    "    'BloodPressure',\n",
    "    'SkinThickness',\n",
    "    'Insulin',\n",
    "    'BMI'\n",
    "]\n",
    "x_df = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    "y_df = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f96444c7-4f11-404f-ab12-05f99558d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into 15% test, 85% train \n",
    "x_temp, x_test, y_temp, y_test = train_test_split(x_df, y_df, test_size=0.15, random_state=1)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_temp, y_temp, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260afc0f-7762-425c-9830-07bc0caf3c66",
   "metadata": {},
   "source": [
    "# Regresi√≥n Logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb0ac9-4ed3-4db4-a9e1-78a6b6428f03",
   "metadata": {},
   "source": [
    "### Con los datos sin procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b621efc2-1e46-4e1f-b893-286936dc41e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'basic'\n",
    "checkdir = join(checkpoints_path,name)\n",
    "tensordir = join(tensor_path, name)\n",
    "\n",
    "model_0 = Sequential()\n",
    "model_0.add(Dense(units=1, activation='sigmoid', input_shape=(x_train.shape[1],)))\n",
    "model_0.compile(optimizer=SGD(), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52654670-1384-4ad2-bd9d-8aa80ffb02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkdir,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_auc',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "tensor_call = TensorBoard(log_dir=tensordir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4598cf58-c66b-476e-8c70-94ba0440b9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.3841s). Check your callbacks.\n",
      "Wall time: 9.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Valor Predictivo Positivo</th>\n",
       "      <th>Valor Predictivo Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.621374</td>\n",
       "      <td>0.753463</td>\n",
       "      <td>0.398964</td>\n",
       "      <td>0.463855</td>\n",
       "      <td>0.701031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validacion</td>\n",
       "      <td>0.702665</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Set   AUC ROC  Especificidad  Sensibilidad  \\\n",
       "0       Train  0.621374       0.753463      0.398964   \n",
       "1  Validacion  0.702665       0.812500      0.617647   \n",
       "\n",
       "   Valor Predictivo Positivo  Valor Predictivo Negativo  \n",
       "0                   0.463855                   0.701031  \n",
       "1                   0.636364                   0.800000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "history = model_0.fit(x_train, y_train, epochs=50, \n",
    "            validation_data=(x_valid, y_valid),\n",
    "            callbacks=[model_0_checkpoint_callback, tensor_call],\n",
    "            verbose=0)\n",
    "# Cargo el mejor modelo entrenado\n",
    "model_0.load_weights(checkdir)\n",
    "verify_model(model_0, x_train, y_train, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eb015e-e6e3-4830-b3bc-4d5508681280",
   "metadata": {},
   "source": [
    "### Reemplazando datos invalidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "327a79bd-6158-41bc-a482-70fb9e6670e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_nonzero, _data = replace_outliers_zeros(x_train, {}, zeros, mean_median=True)\n",
    "x_test_nonzero, _data = replace_outliers_zeros(x_test, {}, zeros, mean_median=True, data_to_replace=_data)\n",
    "x_valid_nonzero, _data = replace_outliers_zeros(x_valid, {}, zeros, mean_median=True, data_to_replace=_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "766ce494-3dd4-4739-9bb6-fd8b85678173",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'valid'\n",
    "checkdir = join(checkpoints_path, name)\n",
    "tensordir = join(tensor_path, name)\n",
    "tensor_call = TensorBoard(log_dir=tensordir)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(units=1, activation='sigmoid', input_shape=(x_train.shape[1],)))\n",
    "model_1.compile(optimizer=SGD(), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "\n",
    "model_1_checkpoint_callback = ModelCheckpoint(filepath=checkdir,\n",
    "                                              save_weights_only=True,\n",
    "                                              monitor='val_auc',\n",
    "                                              mode='max',\n",
    "                                              save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8135746f-3694-4074-bbc1-12601b43f62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.9387s). Check your callbacks.\n",
      "Wall time: 11.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Valor Predictivo Positivo</th>\n",
       "      <th>Valor Predictivo Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.712292</td>\n",
       "      <td>0.698061</td>\n",
       "      <td>0.647668</td>\n",
       "      <td>0.534188</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validacion</td>\n",
       "      <td>0.736213</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.793103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Set   AUC ROC  Especificidad  Sensibilidad  \\\n",
       "0       Train  0.712292       0.698061      0.647668   \n",
       "1  Validacion  0.736213       0.718750      0.647059   \n",
       "\n",
       "   Valor Predictivo Positivo  Valor Predictivo Negativo  \n",
       "0                   0.534188                   0.787500  \n",
       "1                   0.550000                   0.793103  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "history = model_1.fit(x_train_nonzero, y_train, epochs=50, validation_data=(x_valid_nonzero, y_valid), callbacks=[model_1_checkpoint_callback, tensor_call], verbose=0)\n",
    "# Cargo el mejor modelo entrenado\n",
    "model_1.load_weights(checkdir)\n",
    "verify_model(model_1, x_train_nonzero, y_train, x_valid_nonzero, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e4810-5efa-4e6c-afdc-0666487445e2",
   "metadata": {},
   "source": [
    "Se puede observar como en ambos casos se obtuvo un mejor resultado en validacion que en train, lo cual es un comportamiento que se puede considerar poco esperado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c688b-b1d0-4f85-923c-98bf24734783",
   "metadata": {},
   "source": [
    "### Reemplazando outlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2014a72c-5c8e-4d9a-ad58-ff67a92ddfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_clean, _data = replace_outliers_zeros(x_train, outlayers, zeros, mean_median=True)\n",
    "x_test_clean, _data = replace_outliers_zeros(x_test, outlayers, zeros, mean_median=True, data_to_replace=_data)\n",
    "x_valid_clean, _data = replace_outliers_zeros(x_valid, outlayers, zeros, mean_median=True, data_to_replace=_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75c6a12f-ce70-4b7e-856d-0aa8972025bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'sin_outlayers'\n",
    "checkdir = join(checkpoints_path, name)\n",
    "tensordir = join(tensor_path, name)\n",
    "tensor_call = TensorBoard(log_dir=tensordir)\n",
    "\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(units=1, activation='sigmoid', input_shape=(x_train_clean.shape[1],)))\n",
    "model_2.compile(optimizer=SGD(), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "\n",
    "model_2_checkpoint_callback = ModelCheckpoint(filepath=checkdir,\n",
    "                                              save_weights_only=True,\n",
    "                                              monitor='val_auc',\n",
    "                                              mode='max',\n",
    "                                              save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2db2cb8-fb74-41dd-8907-826aa8597ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.9089s). Check your callbacks.\n",
      "Wall time: 10.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Valor Predictivo Positivo</th>\n",
       "      <th>Valor Predictivo Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.706149</td>\n",
       "      <td>0.739612</td>\n",
       "      <td>0.621762</td>\n",
       "      <td>0.560748</td>\n",
       "      <td>0.785294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validacion</td>\n",
       "      <td>0.743107</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Set   AUC ROC  Especificidad  Sensibilidad  \\\n",
       "0       Train  0.706149       0.739612      0.621762   \n",
       "1  Validacion  0.743107       0.812500      0.588235   \n",
       "\n",
       "   Valor Predictivo Positivo  Valor Predictivo Negativo  \n",
       "0                   0.560748                   0.785294  \n",
       "1                   0.625000                   0.787879  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "history = model_2.fit(x_train_clean, y_train, epochs=50, validation_data=(x_valid_clean, y_valid), callbacks=[model_2_checkpoint_callback, tensor_call], verbose=0)\n",
    "# Cargo el mejor modelo entrenado\n",
    "model_2.load_weights(checkdir)\n",
    "verify_model(model_2, x_train_clean, y_train, x_valid_clean, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a487b457-269d-4f3d-814e-98fd0af19993",
   "metadata": {},
   "source": [
    "### Normalizando los datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fea150e4-b87b-4156-9ea2-98d39e5ce6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm, _norm_dict = normalize(x_train_clean, None)\n",
    "x_valid_norm, _norm_dict = normalize(x_valid_clean, _norm_dict)\n",
    "x_test_norm, _norm_dict = normalize(x_test_clean, _norm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3bcf57e-2935-4ac8-8813-12d0df578514",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'normalizado'\n",
    "checkdir = join(checkpoints_path, name)\n",
    "tensordir = join(tensor_path, name)\n",
    "tensor_call = TensorBoard(log_dir=tensordir)\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(Dense(units=1, activation='sigmoid', input_shape=(x_train_norm.shape[1],)))\n",
    "model_3.compile(optimizer=SGD(), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "\n",
    "model_3_checkpoint_callback = ModelCheckpoint(filepath=checkdir,\n",
    "                                              save_weights_only=True,\n",
    "                                              monitor='val_auc',\n",
    "                                              mode='max',\n",
    "                                              save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6181c20-7e99-4c09-bd34-9935caf9c39f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 2/18 [==>...........................] - ETA: 7s - loss: 1.3577 - auc: 0.2021WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.9720s). Check your callbacks.\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.2562 - auc: 0.1984 - val_loss: 1.1417 - val_auc: 0.2429\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1.1585 - auc: 0.2021 - val_loss: 1.0578 - val_auc: 0.2500\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1.0702 - auc: 0.2087 - val_loss: 0.9827 - val_auc: 0.2633\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.9925 - auc: 0.2192 - val_loss: 0.9175 - val_auc: 0.2748\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.9248 - auc: 0.2332 - val_loss: 0.8612 - val_auc: 0.2893\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.8671 - auc: 0.2554 - val_loss: 0.8122 - val_auc: 0.3171\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.8173 - auc: 0.2860 - val_loss: 0.7705 - val_auc: 0.3559\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.7746 - auc: 0.3274 - val_loss: 0.7348 - val_auc: 0.4097\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.7382 - auc: 0.3840 - val_loss: 0.7052 - val_auc: 0.4678\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.7082 - auc: 0.4467 - val_loss: 0.6810 - val_auc: 0.5278\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.6831 - auc: 0.5111 - val_loss: 0.6605 - val_auc: 0.5767\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6617 - auc: 0.5718 - val_loss: 0.6427 - val_auc: 0.6206\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6437 - auc: 0.6230 - val_loss: 0.6280 - val_auc: 0.6553\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.6279 - auc: 0.6624 - val_loss: 0.6152 - val_auc: 0.6813\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.6143 - auc: 0.6938 - val_loss: 0.6039 - val_auc: 0.7024\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6026 - auc: 0.7168 - val_loss: 0.5936 - val_auc: 0.7229\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5920 - auc: 0.7353 - val_loss: 0.5846 - val_auc: 0.7344\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5829 - auc: 0.7498 - val_loss: 0.5769 - val_auc: 0.7433\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5748 - auc: 0.7602 - val_loss: 0.5702 - val_auc: 0.7546\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5679 - auc: 0.7685 - val_loss: 0.5640 - val_auc: 0.7622\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.5612 - auc: 0.7762 - val_loss: 0.5585 - val_auc: 0.7672\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5557 - auc: 0.7837 - val_loss: 0.5537 - val_auc: 0.7739\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5507 - auc: 0.7876 - val_loss: 0.5492 - val_auc: 0.7799\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5460 - auc: 0.7915 - val_loss: 0.5449 - val_auc: 0.7835\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5416 - auc: 0.7955 - val_loss: 0.5411 - val_auc: 0.7902\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5378 - auc: 0.7985 - val_loss: 0.5373 - val_auc: 0.7923\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5342 - auc: 0.8016 - val_loss: 0.5343 - val_auc: 0.7927\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5308 - auc: 0.8041 - val_loss: 0.5312 - val_auc: 0.7969\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5277 - auc: 0.8066 - val_loss: 0.5283 - val_auc: 0.7992\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5249 - auc: 0.8086 - val_loss: 0.5256 - val_auc: 0.7999\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5224 - auc: 0.8102 - val_loss: 0.5230 - val_auc: 0.8012\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5199 - auc: 0.8124 - val_loss: 0.5207 - val_auc: 0.8028\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5176 - auc: 0.8135 - val_loss: 0.5188 - val_auc: 0.8035\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5155 - auc: 0.8149 - val_loss: 0.5167 - val_auc: 0.8033\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.5135 - auc: 0.8161 - val_loss: 0.5148 - val_auc: 0.8038\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.5116 - auc: 0.8173 - val_loss: 0.5134 - val_auc: 0.8047\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.5099 - auc: 0.8181 - val_loss: 0.5119 - val_auc: 0.8056\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5084 - auc: 0.8190 - val_loss: 0.5105 - val_auc: 0.8051\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.5069 - auc: 0.8198 - val_loss: 0.5091 - val_auc: 0.8058\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.5054 - auc: 0.8204 - val_loss: 0.5076 - val_auc: 0.8065\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5042 - auc: 0.8212 - val_loss: 0.5067 - val_auc: 0.8079\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5029 - auc: 0.8217 - val_loss: 0.5052 - val_auc: 0.8093\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5016 - auc: 0.8227 - val_loss: 0.5042 - val_auc: 0.8097\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5005 - auc: 0.8236 - val_loss: 0.5030 - val_auc: 0.8104\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4994 - auc: 0.8240 - val_loss: 0.5020 - val_auc: 0.8118\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4984 - auc: 0.8247 - val_loss: 0.5010 - val_auc: 0.8130\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4975 - auc: 0.8252 - val_loss: 0.5000 - val_auc: 0.8146\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4965 - auc: 0.8257 - val_loss: 0.4990 - val_auc: 0.8134\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4956 - auc: 0.8266 - val_loss: 0.4981 - val_auc: 0.8143\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4946 - auc: 0.8269 - val_loss: 0.4977 - val_auc: 0.8159\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4940 - auc: 0.8275 - val_loss: 0.4971 - val_auc: 0.8148\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4932 - auc: 0.8281 - val_loss: 0.4964 - val_auc: 0.8166\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4924 - auc: 0.8287 - val_loss: 0.4957 - val_auc: 0.8143\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4917 - auc: 0.8291 - val_loss: 0.4949 - val_auc: 0.8169\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4910 - auc: 0.8296 - val_loss: 0.4941 - val_auc: 0.8171\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4904 - auc: 0.8300 - val_loss: 0.4933 - val_auc: 0.8176\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4897 - auc: 0.8304 - val_loss: 0.4927 - val_auc: 0.8178\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4893 - auc: 0.8309 - val_loss: 0.4921 - val_auc: 0.8180\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4886 - auc: 0.8310 - val_loss: 0.4916 - val_auc: 0.8189\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4881 - auc: 0.8313 - val_loss: 0.4911 - val_auc: 0.8199\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4876 - auc: 0.8312 - val_loss: 0.4906 - val_auc: 0.8203\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4871 - auc: 0.8314 - val_loss: 0.4901 - val_auc: 0.8192\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4866 - auc: 0.8317 - val_loss: 0.4897 - val_auc: 0.8192\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4863 - auc: 0.8319 - val_loss: 0.4890 - val_auc: 0.8189\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4859 - auc: 0.8320 - val_loss: 0.4884 - val_auc: 0.8194\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4855 - auc: 0.8322 - val_loss: 0.4879 - val_auc: 0.8199\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4851 - auc: 0.8324 - val_loss: 0.4875 - val_auc: 0.8215\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4847 - auc: 0.8325 - val_loss: 0.4870 - val_auc: 0.8203\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4844 - auc: 0.8327 - val_loss: 0.4866 - val_auc: 0.8196\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4841 - auc: 0.8327 - val_loss: 0.4862 - val_auc: 0.8208\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4837 - auc: 0.8330 - val_loss: 0.4861 - val_auc: 0.8215\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4833 - auc: 0.8329 - val_loss: 0.4858 - val_auc: 0.8219\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4830 - auc: 0.8331 - val_loss: 0.4855 - val_auc: 0.8224\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4828 - auc: 0.8334 - val_loss: 0.4852 - val_auc: 0.8224\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4824 - auc: 0.8332 - val_loss: 0.4849 - val_auc: 0.8222\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4821 - auc: 0.8335 - val_loss: 0.4846 - val_auc: 0.8215\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4819 - auc: 0.8335 - val_loss: 0.4844 - val_auc: 0.8222\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4815 - auc: 0.8339 - val_loss: 0.4842 - val_auc: 0.8224\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4813 - auc: 0.8341 - val_loss: 0.4839 - val_auc: 0.8238\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4810 - auc: 0.8341 - val_loss: 0.4837 - val_auc: 0.8242\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4807 - auc: 0.8342 - val_loss: 0.4837 - val_auc: 0.8235\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4805 - auc: 0.8341 - val_loss: 0.4835 - val_auc: 0.8240\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4803 - auc: 0.8343 - val_loss: 0.4833 - val_auc: 0.8251\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4801 - auc: 0.8345 - val_loss: 0.4829 - val_auc: 0.8247\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4799 - auc: 0.8345 - val_loss: 0.4825 - val_auc: 0.8256\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4796 - auc: 0.8344 - val_loss: 0.4822 - val_auc: 0.8254\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4794 - auc: 0.8345 - val_loss: 0.4820 - val_auc: 0.8251\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4792 - auc: 0.8347 - val_loss: 0.4820 - val_auc: 0.8251\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4791 - auc: 0.8344 - val_loss: 0.4818 - val_auc: 0.8258\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4789 - auc: 0.8343 - val_loss: 0.4816 - val_auc: 0.8254\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4787 - auc: 0.8345 - val_loss: 0.4815 - val_auc: 0.8254\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4786 - auc: 0.8347 - val_loss: 0.4814 - val_auc: 0.8258\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4784 - auc: 0.8349 - val_loss: 0.4811 - val_auc: 0.8258\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4783 - auc: 0.8348 - val_loss: 0.4810 - val_auc: 0.8254\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4782 - auc: 0.8349 - val_loss: 0.4808 - val_auc: 0.8261\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4780 - auc: 0.8348 - val_loss: 0.4806 - val_auc: 0.8258\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4779 - auc: 0.8352 - val_loss: 0.4803 - val_auc: 0.8258\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4778 - auc: 0.8349 - val_loss: 0.4802 - val_auc: 0.8256\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4777 - auc: 0.8350 - val_loss: 0.4801 - val_auc: 0.8249\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4775 - auc: 0.8350 - val_loss: 0.4800 - val_auc: 0.8251\n",
      "Wall time: 28.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Valor Predictivo Positivo</th>\n",
       "      <th>Valor Predictivo Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.834900</td>\n",
       "      <td>0.872576</td>\n",
       "      <td>0.585492</td>\n",
       "      <td>0.710692</td>\n",
       "      <td>0.797468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validacion</td>\n",
       "      <td>0.825368</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Set   AUC ROC  Especificidad  Sensibilidad  \\\n",
       "0       Train  0.834900       0.872576      0.585492   \n",
       "1  Validacion  0.825368       0.890625      0.470588   \n",
       "\n",
       "   Valor Predictivo Positivo  Valor Predictivo Negativo  \n",
       "0                   0.710692                   0.797468  \n",
       "1                   0.695652                   0.760000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "history = model_3.fit(x_train_norm, y_train, epochs=100, validation_data=(x_valid_norm, y_valid), callbacks=[model_3_checkpoint_callback, tensor_call], verbose=1)\n",
    "# Cargo el mejor modelo entrenado\n",
    "model_3.load_weights(checkdir)\n",
    "verify_model(model_3, x_train_norm, y_train, x_valid_norm, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408242fe-9edc-4b2a-ad2b-aa3b26e315fb",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Los hyperpar√°metrso principales de este callback son:\n",
    "- monitor: indica la variable a monitorear\n",
    "- min_delta: la minima diferencia que se considera como mejora\n",
    "- patience: cantidad de epochs sin mejoras antes de parar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbadadd9-e656-4a72-88c8-b6bae22af543",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = EarlyStopping(monitor='val_auc', patience=20)\n",
    "name = 'early_stop'\n",
    "checkdir = join(checkpoints_path, name)\n",
    "tensordir = join(tensor_path, name)\n",
    "tensor_call = TensorBoard(log_dir=tensordir)\n",
    "model_4_checkpoint_callback = ModelCheckpoint(filepath=checkdir,\n",
    "                                              save_weights_only=True,\n",
    "                                              monitor='val_auc',\n",
    "                                              mode='max',\n",
    "                                              save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f63c91ec-5e52-4679-b00b-9eec8d0460af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 2/18 [==>...........................] - ETA: 4s - loss: 0.4210 - auc: 0.8742WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.5616s). Check your callbacks.\n",
      "18/18 [==============================] - 1s 65ms/step - loss: 0.4780 - auc: 0.8349 - val_loss: 0.4807 - val_auc: 0.8258\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4779 - auc: 0.8349 - val_loss: 0.4804 - val_auc: 0.8258\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4778 - auc: 0.8351 - val_loss: 0.4803 - val_auc: 0.8256\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4777 - auc: 0.8350 - val_loss: 0.4801 - val_auc: 0.8254\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4776 - auc: 0.8348 - val_loss: 0.4798 - val_auc: 0.8258\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4775 - auc: 0.8353 - val_loss: 0.4798 - val_auc: 0.8258\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4774 - auc: 0.8351 - val_loss: 0.4796 - val_auc: 0.8261\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4773 - auc: 0.8349 - val_loss: 0.4797 - val_auc: 0.8249\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4772 - auc: 0.8351 - val_loss: 0.4795 - val_auc: 0.8249\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4770 - auc: 0.8352 - val_loss: 0.4794 - val_auc: 0.8244\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4769 - auc: 0.8352 - val_loss: 0.4793 - val_auc: 0.8235\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4768 - auc: 0.8352 - val_loss: 0.4792 - val_auc: 0.8238\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4767 - auc: 0.8354 - val_loss: 0.4791 - val_auc: 0.8251\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4766 - auc: 0.8356 - val_loss: 0.4792 - val_auc: 0.8251\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4765 - auc: 0.8353 - val_loss: 0.4791 - val_auc: 0.8258\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4765 - auc: 0.8354 - val_loss: 0.4791 - val_auc: 0.8258\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4765 - auc: 0.8353 - val_loss: 0.4791 - val_auc: 0.8254\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4764 - auc: 0.8355 - val_loss: 0.4790 - val_auc: 0.8258\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4762 - auc: 0.8355 - val_loss: 0.4788 - val_auc: 0.8254\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4762 - auc: 0.8357 - val_loss: 0.4787 - val_auc: 0.8249\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4761 - auc: 0.8355 - val_loss: 0.4788 - val_auc: 0.8242\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4760 - auc: 0.8358 - val_loss: 0.4787 - val_auc: 0.8261\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4760 - auc: 0.8359 - val_loss: 0.4786 - val_auc: 0.8249\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4759 - auc: 0.8362 - val_loss: 0.4787 - val_auc: 0.8258\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4758 - auc: 0.8359 - val_loss: 0.4785 - val_auc: 0.8263\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4757 - auc: 0.8360 - val_loss: 0.4784 - val_auc: 0.8277\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4758 - auc: 0.8360 - val_loss: 0.4783 - val_auc: 0.8277\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4757 - auc: 0.8359 - val_loss: 0.4783 - val_auc: 0.8272\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4756 - auc: 0.8360 - val_loss: 0.4782 - val_auc: 0.8270\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4756 - auc: 0.8361 - val_loss: 0.4782 - val_auc: 0.8270\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4756 - auc: 0.8362 - val_loss: 0.4783 - val_auc: 0.8258\n",
      "Wall time: 6.12 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Valor Predictivo Positivo</th>\n",
       "      <th>Valor Predictivo Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.836063</td>\n",
       "      <td>0.869806</td>\n",
       "      <td>0.580311</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>0.794937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validacion</td>\n",
       "      <td>0.826746</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Set   AUC ROC  Especificidad  Sensibilidad  \\\n",
       "0       Train  0.836063       0.869806      0.580311   \n",
       "1  Validacion  0.826746       0.906250      0.470588   \n",
       "\n",
       "   Valor Predictivo Positivo  Valor Predictivo Negativo  \n",
       "0                   0.704403                   0.794937  \n",
       "1                   0.727273                   0.763158  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "history = model_3.fit(x_train_norm, y_train, epochs=50, validation_data=(x_valid_norm, y_valid), callbacks=[model_4_checkpoint_callback, stop_early, tensor_call], verbose=1)\n",
    "# Cargo el mejor modelo entrenado\n",
    "model_3.load_weights(checkdir)\n",
    "verify_model(model_3, x_train_norm, y_train, x_valid_norm, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ee5fa-bcd0-41de-9588-33f3e55f0908",
   "metadata": {},
   "source": [
    "Se puede evidenciar como al utilizar early stopping el entrenamiento finaliza antes debido a que las mejoras son reducidas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a9a501-188e-462b-8ad2-ed273f304e93",
   "metadata": {},
   "source": [
    "## Ajuste de Hyperpar√°metros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e3557e-048b-4a0c-a28a-fac522777877",
   "metadata": {},
   "source": [
    "### Learning rate\n",
    "Por defecto en SGD el learning rate que utiliza keras es 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "395d5ccf-f5ac-4e87-ab09-1d2a7d1a70a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L_r</th>\n",
       "      <th>1e-05</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.22</th>\n",
       "      <th>0.33</th>\n",
       "      <th>0.47</th>\n",
       "      <th>0.56</th>\n",
       "      <th>0.81</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.8</th>\n",
       "      <th>2.2</th>\n",
       "      <th>2.7</th>\n",
       "      <th>3.3</th>\n",
       "      <th>4.7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.461397</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.606158</td>\n",
       "      <td>0.668199</td>\n",
       "      <td>0.836857</td>\n",
       "      <td>0.829504</td>\n",
       "      <td>0.83364</td>\n",
       "      <td>0.835478</td>\n",
       "      <td>0.832721</td>\n",
       "      <td>0.840533</td>\n",
       "      <td>0.846507</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.842831</td>\n",
       "      <td>0.850184</td>\n",
       "      <td>0.849265</td>\n",
       "      <td>0.847886</td>\n",
       "      <td>0.841452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epochs</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      L_r      1e-05     0.0001      0.001       0.01       0.05        0.1  \\\n",
       "0     AUC   0.461397   0.328125   0.606158   0.668199   0.836857   0.829504   \n",
       "1  Epochs  30.000000  20.000000  20.000000  20.000000  20.000000  20.000000   \n",
       "\n",
       "       0.22       0.33       0.47       0.56       0.81       1.2        1.8  \\\n",
       "0   0.83364   0.835478   0.832721   0.840533   0.846507   0.84375   0.842831   \n",
       "1  20.00000  20.000000  20.000000  23.000000  40.000000  44.00000  32.000000   \n",
       "\n",
       "         2.2        2.7        3.3        4.7  \n",
       "0   0.850184   0.849265   0.847886   0.841452  \n",
       "1  29.000000  23.000000  35.000000  20.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates = [1e-5, 1e-4, 1e-3, 0.01, 0.05, 0.1, 0.22, 0.33, 0.47, 0.56, 0.81, 1.2, 1.8, 2.2, 2.7, 3.3, 4.7]\n",
    "\n",
    "arr_of_metrics = []\n",
    "auc_res = {'L_r':['AUC', 'Epochs']}\n",
    "best = 0\n",
    "best_name = ''\n",
    "for i in learning_rates:\n",
    "    name = 'learning_{}'.format(i)\n",
    "    checkdir = join(checkpoints_path, name)\n",
    "    tensordir = join(tensor_path, name)\n",
    "    tensor_call = TensorBoard(log_dir=tensordir)\n",
    "    learning_checkpoint_callback = ModelCheckpoint(filepath=checkdir,\n",
    "                                                  save_weights_only=True,\n",
    "                                                  monitor='val_auc',\n",
    "                                                  mode='max',\n",
    "                                                  save_best_only=True)\n",
    "\n",
    "\n",
    "    learning = Sequential()\n",
    "    learning.add(Dense(units=1, activation='sigmoid', input_shape=(x_train_norm.shape[1],)))\n",
    "    learning.compile(optimizer=SGD(learning_rate=i), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "\n",
    "    history = learning.fit(x_train_norm, y_train, epochs=100, validation_data=(x_valid_norm, y_valid), callbacks=[learning_checkpoint_callback, stop_early, tensor_call], \n",
    "                          verbose=1)\n",
    "    # Cargo el mejor modelo entrenado\n",
    "    learning.load_weights(checkdir)\n",
    "    metrics = verify_model(learning, x_train_norm, y_train, x_valid_norm, y_valid)\n",
    "    arr_of_metrics.append(metrics)\n",
    "    auc_res[i] = [metrics['AUC ROC'][1], history.epoch[-1]]\n",
    "    if best < auc_res[i][0]:\n",
    "        best_name = checkdir\n",
    "        best = auc_res[i][0]\n",
    "    clear_output(wait=True)\n",
    "pd.DataFrame(data=auc_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148c693d-5ced-4d02-9f0c-cbffdc8865ef",
   "metadata": {},
   "source": [
    "Es interesante observar como para los learning rate mas chicos, el entrenamiento se corta debido al early stoping en los primeros 15 epochs, ya que dentro de esos primeros 15 las mejoras son pocas debido a su avance \"suave\", en comparaci√≥n con los learning rates mas altos que obtienen una mejor optimizaci√≥n en mayor cantidad de epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4929729c-527d-48a2-9fab-6d386c4459a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Valor Predictivo Positivo</th>\n",
       "      <th>Valor Predictivo Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.803511</td>\n",
       "      <td>0.878116</td>\n",
       "      <td>0.544041</td>\n",
       "      <td>0.704698</td>\n",
       "      <td>0.782716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validacion</td>\n",
       "      <td>0.850184</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.763889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Set   AUC ROC  Especificidad  Sensibilidad  \\\n",
       "0       Train  0.803511       0.878116      0.544041   \n",
       "1  Validacion  0.850184       0.859375      0.500000   \n",
       "\n",
       "   Valor Predictivo Positivo  Valor Predictivo Negativo  \n",
       "0                   0.704698                   0.782716  \n",
       "1                   0.653846                   0.763889  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargo el mejor modelo entrenado\n",
    "learning.load_weights(best_name)\n",
    "verify_model(learning, x_train_norm, y_train, x_valid_norm, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda72e22-b250-42a4-9b25-86bd03a55432",
   "metadata": {},
   "source": [
    "#### Scheduling learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "870f4f4a-1b11-49ac-bab0-c6fad28b66c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_schedule = ExponentialDecay(initial_learning_rate=2.7, decay_steps=100, decay_rate=0.96)\n",
    "name = 'exponetial'\n",
    "checkdir = join(checkpoints_path, name)\n",
    "tensordir = join(tensor_path, name)\n",
    "tensor_call = TensorBoard(log_dir=tensordir)\n",
    "    \n",
    "exponential_checkpoint_callback = ModelCheckpoint(filepath=checkdir,\n",
    "                                                  save_weights_only=True,\n",
    "                                                  monitor='val_auc',\n",
    "                                                  mode='max',\n",
    "                                                  save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cff760f6-fc34-473f-81ec-f0503d1040bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = Sequential()\n",
    "learning.add(Dense(units=1, activation='sigmoid', input_shape=(x_train_norm.shape[1],)))\n",
    "learning.compile(optimizer=SGD(learning_rate=learning_schedule), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "866b9b27-42b3-4710-97b4-c00840ee77b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 2/18 [==>...........................] - ETA: 7s - loss: 0.7433 - auc: 0.6427WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.9779s). Check your callbacks.\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.5665 - auc: 0.7716 - val_loss: 0.5172 - val_auc: 0.8169\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5276 - auc: 0.8016 - val_loss: 0.5029 - val_auc: 0.8038\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5163 - auc: 0.8091 - val_loss: 0.5128 - val_auc: 0.8028\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5215 - auc: 0.8055 - val_loss: 0.5301 - val_auc: 0.7865\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5255 - auc: 0.8089 - val_loss: 0.6183 - val_auc: 0.7385\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5409 - auc: 0.7941 - val_loss: 0.5768 - val_auc: 0.7279\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5187 - auc: 0.8012 - val_loss: 0.5052 - val_auc: 0.8433\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5218 - auc: 0.8107 - val_loss: 0.4868 - val_auc: 0.8428\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5162 - auc: 0.8125 - val_loss: 0.5629 - val_auc: 0.7601\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5494 - auc: 0.7920 - val_loss: 0.5224 - val_auc: 0.7877\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5265 - auc: 0.8018 - val_loss: 0.6710 - val_auc: 0.7321\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5373 - auc: 0.8015 - val_loss: 0.5412 - val_auc: 0.8049\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5300 - auc: 0.7960 - val_loss: 0.5688 - val_auc: 0.7695\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5198 - auc: 0.8025 - val_loss: 0.5020 - val_auc: 0.8068\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5074 - auc: 0.8103 - val_loss: 0.4940 - val_auc: 0.8286\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5170 - auc: 0.8182 - val_loss: 0.5145 - val_auc: 0.8242\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5095 - auc: 0.8173 - val_loss: 0.4734 - val_auc: 0.8357\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5257 - auc: 0.8034 - val_loss: 0.5790 - val_auc: 0.7551\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5208 - auc: 0.8059 - val_loss: 0.5007 - val_auc: 0.8102\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5218 - auc: 0.8043 - val_loss: 0.5723 - val_auc: 0.7608\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5202 - auc: 0.8089 - val_loss: 0.5164 - val_auc: 0.8033\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5306 - auc: 0.7952 - val_loss: 0.5078 - val_auc: 0.8123\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5171 - auc: 0.8045 - val_loss: 0.4790 - val_auc: 0.8240\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5288 - auc: 0.8018 - val_loss: 0.5435 - val_auc: 0.7966\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4960 - auc: 0.8186 - val_loss: 0.7397 - val_auc: 0.5777\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5315 - auc: 0.7940 - val_loss: 0.5086 - val_auc: 0.8130\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5149 - auc: 0.8078 - val_loss: 0.4931 - val_auc: 0.8302\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5117 - auc: 0.8121 - val_loss: 0.5128 - val_auc: 0.8355\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5332 - auc: 0.7909 - val_loss: 0.5603 - val_auc: 0.7723\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5063 - auc: 0.8106 - val_loss: 0.5034 - val_auc: 0.8231\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5137 - auc: 0.8102 - val_loss: 0.5414 - val_auc: 0.7902\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5243 - auc: 0.8044 - val_loss: 0.5437 - val_auc: 0.8015\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5114 - auc: 0.8118 - val_loss: 0.4842 - val_auc: 0.8300\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5130 - auc: 0.8072 - val_loss: 0.5143 - val_auc: 0.8022\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5183 - auc: 0.8065 - val_loss: 0.5381 - val_auc: 0.7691\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4911 - auc: 0.8224 - val_loss: 0.5146 - val_auc: 0.7980\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5068 - auc: 0.8159 - val_loss: 0.6588 - val_auc: 0.6301\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5265 - auc: 0.8031 - val_loss: 0.5133 - val_auc: 0.8068\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5096 - auc: 0.8147 - val_loss: 0.5532 - val_auc: 0.7700\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5128 - auc: 0.8146 - val_loss: 0.5788 - val_auc: 0.7486\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5151 - auc: 0.8110 - val_loss: 0.5707 - val_auc: 0.7383\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5173 - auc: 0.8005 - val_loss: 0.4939 - val_auc: 0.8072\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5116 - auc: 0.8086 - val_loss: 0.4829 - val_auc: 0.8311\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5021 - auc: 0.8138 - val_loss: 0.5373 - val_auc: 0.7812\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5047 - auc: 0.8177 - val_loss: 0.5279 - val_auc: 0.7925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Valor Predictivo Positivo</th>\n",
       "      <th>Valor Predictivo Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.814677</td>\n",
       "      <td>0.844875</td>\n",
       "      <td>0.601036</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.798429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validacion</td>\n",
       "      <td>0.842831</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.811594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Set   AUC ROC  Especificidad  Sensibilidad  \\\n",
       "0       Train  0.814677       0.844875      0.601036   \n",
       "1  Validacion  0.842831       0.875000      0.617647   \n",
       "\n",
       "   Valor Predictivo Positivo  Valor Predictivo Negativo  \n",
       "0                   0.674419                   0.798429  \n",
       "1                   0.724138                   0.811594  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = learning.fit(x_train_norm, y_train, epochs=100, validation_data=(x_valid_norm, y_valid), callbacks=[exponential_checkpoint_callback, stop_early, tensor_call], \n",
    "                      verbose=1)\n",
    "# Cargo el mejor modelo entrenado\n",
    "learning.load_weights(checkdir)\n",
    "verify_model(learning, x_train_norm, y_train, x_valid_norm, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae8dcc-b7db-41f9-aaae-0e13d7e088bb",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe822c23-754d-4341-9f34-6974ec35c7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>momentum</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.85</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.95</th>\n",
       "      <th>0.99</th>\n",
       "      <th>0.999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.851103</td>\n",
       "      <td>0.84421</td>\n",
       "      <td>0.840074</td>\n",
       "      <td>0.84421</td>\n",
       "      <td>0.837776</td>\n",
       "      <td>0.809972</td>\n",
       "      <td>0.769761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epochs</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  momentum        0.5       0.6       0.85       0.9       0.95       0.99  \\\n",
       "0      AUC   0.851103   0.84421   0.840074   0.84421   0.837776   0.809972   \n",
       "1   Epochs  99.000000  99.00000  99.000000  99.00000  99.000000  99.000000   \n",
       "\n",
       "       0.999  \n",
       "0   0.769761  \n",
       "1  99.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momentum_arr = [0.5, 0.6, 0.85, 0.9, 0.95, 0.99, 0.999]\n",
    "\n",
    "arr_of_metrics = []\n",
    "auc_res = {'momentum':['AUC', 'Epochs']}\n",
    "for i in momentum_arr:\n",
    "    name = 'momentum_{}'.format(i)\n",
    "    checkdir = join(checkpoints_path, name)\n",
    "    tensordir = join(tensor_path, name)\n",
    "    tensor_call = TensorBoard(log_dir=tensordir)\n",
    "\n",
    "    momentum_checkpoint_callback = ModelCheckpoint(filepath=checkdir,\n",
    "                                                  save_weights_only=True,\n",
    "                                                  monitor='val_auc',\n",
    "                                                  mode='max',\n",
    "                                                  save_best_only=True)\n",
    "    \n",
    "    mom_model = Sequential()\n",
    "    mom_model.add(Dense(units=1, activation='sigmoid', input_shape=(x_train_norm.shape[1],)))\n",
    "    mom_model.compile(optimizer=SGD(learning_rate=learning_schedule, momentum=i), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "\n",
    "    history = mom_model.fit(x_train_norm, y_train, epochs=100, validation_data=(x_valid_norm, y_valid), callbacks=[momentum_checkpoint_callback, tensor_call], \n",
    "                          verbose=1)\n",
    "    # Cargo el mejor modelo entrenado\n",
    "    mom_model.load_weights(checkdir)\n",
    "    metrics = verify_model(mom_model, x_train_norm, y_train, x_valid_norm, y_valid)\n",
    "    arr_of_metrics.append(metrics)\n",
    "    auc_res[i] = [metrics['AUC ROC'][1], history.epoch[-1]]\n",
    "    clear_output(wait=True)\n",
    "pd.DataFrame(data=auc_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7d59387-5621-4e2b-a346-91c841da2933",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 2/18 [==>...........................] - ETA: 13s - loss: 0.5730 - auc: 0.8163WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 1.7510s). Check your callbacks.\n",
      "18/18 [==============================] - 3s 156ms/step - loss: 0.5802 - auc: 0.7835 - val_loss: 0.6617 - val_auc: 0.7553\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6116 - auc: 0.7790 - val_loss: 0.6057 - val_auc: 0.7378\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5798 - auc: 0.7850 - val_loss: 0.6375 - val_auc: 0.8035\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6498 - auc: 0.7699 - val_loss: 0.7918 - val_auc: 0.5935\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6169 - auc: 0.7718 - val_loss: 0.4840 - val_auc: 0.8217\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6029 - auc: 0.7794 - val_loss: 0.6742 - val_auc: 0.6719\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6202 - auc: 0.7690 - val_loss: 0.5496 - val_auc: 0.7838\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5859 - auc: 0.7817 - val_loss: 0.6283 - val_auc: 0.7360\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5806 - auc: 0.7732 - val_loss: 0.8296 - val_auc: 0.7624\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6519 - auc: 0.7700 - val_loss: 0.5700 - val_auc: 0.8118\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5700 - auc: 0.7897 - val_loss: 0.6043 - val_auc: 0.7810\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6391 - auc: 0.7756 - val_loss: 0.5583 - val_auc: 0.7865\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5613 - auc: 0.7878 - val_loss: 0.6255 - val_auc: 0.8182\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5736 - auc: 0.7813 - val_loss: 0.6024 - val_auc: 0.7142\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.6274 - auc: 0.7528 - val_loss: 0.4872 - val_auc: 0.8318\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5415 - auc: 0.8003 - val_loss: 0.5532 - val_auc: 0.7493\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6011 - auc: 0.7754 - val_loss: 0.7023 - val_auc: 0.6000\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6187 - auc: 0.7633 - val_loss: 0.5353 - val_auc: 0.8079\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5620 - auc: 0.7985 - val_loss: 0.6400 - val_auc: 0.7771\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6398 - auc: 0.7683 - val_loss: 0.5325 - val_auc: 0.8364\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5844 - auc: 0.7791 - val_loss: 0.5916 - val_auc: 0.7656\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5608 - auc: 0.7910 - val_loss: 0.5362 - val_auc: 0.8336\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5763 - auc: 0.7881 - val_loss: 0.5670 - val_auc: 0.8132\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5803 - auc: 0.7788 - val_loss: 0.5194 - val_auc: 0.8277\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Valor Predictivo Positivo</th>\n",
       "      <th>Valor Predictivo Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.811850</td>\n",
       "      <td>0.817175</td>\n",
       "      <td>0.626943</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.803815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validacion</td>\n",
       "      <td>0.836397</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.830769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Set   AUC ROC  Especificidad  Sensibilidad  \\\n",
       "0       Train  0.811850       0.817175      0.626943   \n",
       "1  Validacion  0.836397       0.843750      0.676471   \n",
       "\n",
       "   Valor Predictivo Positivo  Valor Predictivo Negativo  \n",
       "0                   0.647059                   0.803815  \n",
       "1                   0.696970                   0.830769  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'momentum'\n",
    "checkdir = join(checkpoints_path, name)\n",
    "tensordir = join(tensor_path, name)\n",
    "tensor_call = TensorBoard(log_dir=tensordir)\n",
    "momentum_checkpoint_callback = ModelCheckpoint(filepath=checkdir,\n",
    "                                                  save_weights_only=True,\n",
    "                                                  monitor='val_auc',\n",
    "                                                  mode='max',\n",
    "                                                  save_best_only=True)\n",
    "\n",
    "mom_model = Sequential()\n",
    "mom_model.add(Dense(units=1, activation='sigmoid', input_shape=(x_train_norm.shape[1],)))\n",
    "mom_model.compile(optimizer=SGD(learning_rate=learning_schedule, momentum=0.6), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "history = mom_model.fit(x_train_norm, y_train, epochs=100, validation_data=(x_valid_norm, y_valid), callbacks=[momentum_checkpoint_callback, stop_early, tensor_call], \n",
    "                          verbose=1)\n",
    "# Cargo el mejor modelo entrenado\n",
    "mom_model.load_weights(checkdir)\n",
    "verify_model(mom_model, x_train_norm, y_train, x_valid_norm, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53ea140-5003-4229-bf84-97204524d602",
   "metadata": {},
   "source": [
    "### Optimizador Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98d5107a-2ea2-4201-829a-ed8e444f7f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 42s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L_r</th>\n",
       "      <th>1e-05</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.22</th>\n",
       "      <th>0.33</th>\n",
       "      <th>0.47</th>\n",
       "      <th>0.56</th>\n",
       "      <th>0.81</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.8</th>\n",
       "      <th>2.2</th>\n",
       "      <th>2.7</th>\n",
       "      <th>3.3</th>\n",
       "      <th>4.7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.349265</td>\n",
       "      <td>0.542739</td>\n",
       "      <td>0.82261</td>\n",
       "      <td>0.832261</td>\n",
       "      <td>0.837776</td>\n",
       "      <td>0.842371</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.847426</td>\n",
       "      <td>0.848346</td>\n",
       "      <td>0.848346</td>\n",
       "      <td>0.84329</td>\n",
       "      <td>0.846048</td>\n",
       "      <td>0.839614</td>\n",
       "      <td>0.837776</td>\n",
       "      <td>0.828585</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.824908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epochs</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      L_r      1e-05     0.0001     0.001       0.01       0.05        0.1  \\\n",
       "0     AUC   0.349265   0.542739   0.82261   0.832261   0.837776   0.842371   \n",
       "1  Epochs  99.000000  99.000000  99.00000  99.000000  99.000000  99.000000   \n",
       "\n",
       "       0.22       0.33       0.47       0.56      0.81        1.2        1.8  \\\n",
       "0   0.84375   0.847426   0.848346   0.848346   0.84329   0.846048   0.839614   \n",
       "1  99.00000  99.000000  99.000000  99.000000  99.00000  99.000000  99.000000   \n",
       "\n",
       "         2.2        2.7       3.3        4.7  \n",
       "0   0.837776   0.828585   0.84375   0.824908  \n",
       "1  99.000000  99.000000  99.00000  99.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "adam_lr = [1e-5, 1e-4, 1e-3, 0.01, 0.05, 0.1, 0.22, 0.33, 0.47, 0.56, 0.81, 1.2, 1.8, 2.2, 2.7, 3.3, 4.7]\n",
    "\n",
    "arr_of_metrics = []\n",
    "auc_res = {'L_r':['AUC', 'Epochs']}\n",
    "for i in adam_lr:\n",
    "    name = 'Adam_{}'.format(i)\n",
    "    checkdir = join(checkpoints_path, name)\n",
    "    tensordir = join(tensor_path, name)\n",
    "    tensor_call = TensorBoard(log_dir=tensordir)\n",
    "    adam_checkpoint_callback = ModelCheckpoint(filepath=checkdir,\n",
    "                                                  save_weights_only=True,\n",
    "                                                  monitor='val_auc',\n",
    "                                                  mode='max',\n",
    "                                                  save_best_only=True)\n",
    "    adam_mod = Sequential()\n",
    "    adam_mod.add(Dense(units=1, activation='sigmoid', input_shape=(x_train_norm.shape[1],)))\n",
    "    adam_mod.compile(optimizer=Adam(learning_rate=i), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "\n",
    "    history = adam_mod.fit(x_train_norm, y_train, epochs=100, validation_data=(x_valid_norm, y_valid), callbacks=[adam_checkpoint_callback, tensor_call], \n",
    "                          verbose=1, use_multiprocessing=True)\n",
    "    # Cargo el mejor modelo entrenado\n",
    "    adam_mod.load_weights(checkdir)\n",
    "    metrics = verify_model(adam_mod, x_train_norm, y_train, x_valid_norm, y_valid)\n",
    "    arr_of_metrics.append(metrics)\n",
    "    auc_res[i] = [metrics['AUC ROC'][1], history.epoch[-1]]\n",
    "    clear_output(wait=True)\n",
    "pd.DataFrame(data=auc_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66f8e09d-0f11-4f04-b927-c2633137a1f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 2/18 [==>...........................] - ETA: 6s - loss: 2.0819 - auc: 0.6687WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.7599s). Check your callbacks.\n",
      "18/18 [==============================] - 1s 82ms/step - loss: 2.5737 - auc: 0.6936 - val_loss: 2.1725 - val_auc: 0.6675\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2.3818 - auc: 0.6853 - val_loss: 1.9679 - val_auc: 0.7489\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.2700 - auc: 0.7005 - val_loss: 1.5579 - val_auc: 0.6818\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.2543 - auc: 0.6800 - val_loss: 1.1141 - val_auc: 0.7213\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1.6742 - auc: 0.7103 - val_loss: 0.8751 - val_auc: 0.7939\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.8076 - auc: 0.6721 - val_loss: 1.4543 - val_auc: 0.7592\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.8455 - auc: 0.6857 - val_loss: 1.3927 - val_auc: 0.7369\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.5500 - auc: 0.6518 - val_loss: 1.3562 - val_auc: 0.6806\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.6033 - auc: 0.7226 - val_loss: 1.3292 - val_auc: 0.5802\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.6097 - auc: 0.7058 - val_loss: 2.2138 - val_auc: 0.7302\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.0668 - auc: 0.7226 - val_loss: 1.4708 - val_auc: 0.7854\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9071 - auc: 0.7235 - val_loss: 1.1443 - val_auc: 0.7645\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2472 - auc: 0.7129 - val_loss: 1.6230 - val_auc: 0.6009\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.8267 - auc: 0.6936 - val_loss: 2.1569 - val_auc: 0.6746\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.9005 - auc: 0.7002 - val_loss: 1.7803 - val_auc: 0.6898\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1.6071 - auc: 0.7332 - val_loss: 1.2946 - val_auc: 0.8079\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.7903 - auc: 0.7146 - val_loss: 1.6706 - val_auc: 0.7454\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.7168 - auc: 0.7100 - val_loss: 1.4245 - val_auc: 0.6905\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.7507 - auc: 0.7243 - val_loss: 1.9442 - val_auc: 0.7426\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.3990 - auc: 0.7124 - val_loss: 1.1276 - val_auc: 0.7332\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.6202 - auc: 0.7431 - val_loss: 1.6793 - val_auc: 0.6953\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.9687 - auc: 0.7183 - val_loss: 1.3674 - val_auc: 0.6592\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.1194 - auc: 0.6850 - val_loss: 2.1538 - val_auc: 0.7787\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.8311 - auc: 0.7210 - val_loss: 1.4112 - val_auc: 0.5758\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.5855 - auc: 0.7121 - val_loss: 1.2363 - val_auc: 0.6248\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.7264 - auc: 0.7187 - val_loss: 1.2366 - val_auc: 0.5476\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.7164 - auc: 0.7037 - val_loss: 1.6405 - val_auc: 0.7224\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.8735 - auc: 0.6863 - val_loss: 1.2087 - val_auc: 0.7082\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.8600 - auc: 0.6655 - val_loss: 1.0779 - val_auc: 0.7881\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4582 - auc: 0.7213 - val_loss: 0.9934 - val_auc: 0.7362\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6751 - auc: 0.7088 - val_loss: 1.2028 - val_auc: 0.7822\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2224 - auc: 0.7126 - val_loss: 1.4732 - val_auc: 0.6211\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.5939 - auc: 0.7301 - val_loss: 1.1093 - val_auc: 0.6560\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1.7578 - auc: 0.6938 - val_loss: 1.3354 - val_auc: 0.8182\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.5174 - auc: 0.6809 - val_loss: 1.3382 - val_auc: 0.7852\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.2805 - auc: 0.7334 - val_loss: 1.0006 - val_auc: 0.7652\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.6250 - auc: 0.7164 - val_loss: 1.2697 - val_auc: 0.7753\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.2473 - auc: 0.7106 - val_loss: 1.0734 - val_auc: 0.7335\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.9435 - auc: 0.7469 - val_loss: 1.0775 - val_auc: 0.8157\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5175 - auc: 0.7208 - val_loss: 1.2247 - val_auc: 0.7006\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.4052 - auc: 0.7074 - val_loss: 0.9369 - val_auc: 0.7992\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6245 - auc: 0.7142 - val_loss: 1.9704 - val_auc: 0.6057\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.6730 - auc: 0.6940 - val_loss: 1.1337 - val_auc: 0.7645\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.4994 - auc: 0.7378 - val_loss: 1.2868 - val_auc: 0.8171\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.6412 - auc: 0.7057 - val_loss: 2.5091 - val_auc: 0.6455\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6329 - auc: 0.7022 - val_loss: 0.6969 - val_auc: 0.7971\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1606 - auc: 0.7284 - val_loss: 1.8209 - val_auc: 0.7123\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.5477 - auc: 0.7074 - val_loss: 0.9436 - val_auc: 0.8077\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3309 - auc: 0.7323 - val_loss: 1.1907 - val_auc: 0.7640\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6369 - auc: 0.7245 - val_loss: 1.1804 - val_auc: 0.6160\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1.4385 - auc: 0.7104 - val_loss: 0.7556 - val_auc: 0.8382\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7280 - auc: 0.7105 - val_loss: 2.0274 - val_auc: 0.7569\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.8201 - auc: 0.7249 - val_loss: 2.1544 - val_auc: 0.4821\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1637 - auc: 0.7227 - val_loss: 2.4350 - val_auc: 0.4260\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.1645 - auc: 0.6690 - val_loss: 2.0477 - val_auc: 0.6156\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8928 - auc: 0.6549 - val_loss: 1.4593 - val_auc: 0.7004\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.7991 - auc: 0.7067 - val_loss: 1.7483 - val_auc: 0.6728\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6060 - auc: 0.7409 - val_loss: 2.8980 - val_auc: 0.3424\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.6522 - auc: 0.6851 - val_loss: 2.6529 - val_auc: 0.5967\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6589 - auc: 0.7059 - val_loss: 1.4213 - val_auc: 0.7672\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.5162 - auc: 0.7017 - val_loss: 1.4770 - val_auc: 0.6737\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.7336 - auc: 0.7260 - val_loss: 1.4798 - val_auc: 0.7787\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.4404 - auc: 0.7252 - val_loss: 1.0331 - val_auc: 0.6445\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3842 - auc: 0.6902 - val_loss: 1.3056 - val_auc: 0.7707\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.0507 - auc: 0.7164 - val_loss: 2.3811 - val_auc: 0.7052\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.7681 - auc: 0.6993 - val_loss: 1.2742 - val_auc: 0.7661\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.5204 - auc: 0.6991 - val_loss: 1.5350 - val_auc: 0.7197\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.3260 - auc: 0.7406 - val_loss: 0.7849 - val_auc: 0.7266\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4872 - auc: 0.7096 - val_loss: 1.3085 - val_auc: 0.7688\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.4140 - auc: 0.7112 - val_loss: 1.0455 - val_auc: 0.6537\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1788 - auc: 0.7252 - val_loss: 1.0449 - val_auc: 0.7277\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.3424 - auc: 0.7529 - val_loss: 1.5578 - val_auc: 0.6241\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0726 - auc: 0.7302 - val_loss: 1.5818 - val_auc: 0.6266\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.4876 - auc: 0.6977 - val_loss: 1.9905 - val_auc: 0.7521\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5715 - auc: 0.7355 - val_loss: 1.7176 - val_auc: 0.6441\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 1.1035 - auc: 0.7363 - val_loss: 1.4048 - val_auc: 0.6588\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.7618 - auc: 0.6704 - val_loss: 1.6995 - val_auc: 0.7619\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.8128 - auc: 0.7291 - val_loss: 1.2810 - val_auc: 0.7599\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.3381 - auc: 0.7336 - val_loss: 0.8391 - val_auc: 0.7803\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5254 - auc: 0.7160 - val_loss: 1.4645 - val_auc: 0.7210\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6733 - auc: 0.7433 - val_loss: 2.0667 - val_auc: 0.4488\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.4189 - auc: 0.6681 - val_loss: 1.5898 - val_auc: 0.7013\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.4644 - auc: 0.6916 - val_loss: 1.1907 - val_auc: 0.8081\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.7241 - auc: 0.7170 - val_loss: 1.9388 - val_auc: 0.7560\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.4553 - auc: 0.7122 - val_loss: 2.3921 - val_auc: 0.7107\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2.0508 - auc: 0.7047 - val_loss: 2.3269 - val_auc: 0.5131\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.4888 - auc: 0.6808 - val_loss: 1.2458 - val_auc: 0.7723\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.2417 - auc: 0.7309 - val_loss: 1.8909 - val_auc: 0.7008\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.8967 - auc: 0.7118 - val_loss: 1.2858 - val_auc: 0.7181\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1879 - auc: 0.7136 - val_loss: 1.7127 - val_auc: 0.7468\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.7779 - auc: 0.7339 - val_loss: 2.7302 - val_auc: 0.6576\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6810 - auc: 0.6970 - val_loss: 1.2714 - val_auc: 0.7606\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2390 - auc: 0.7038 - val_loss: 1.4671 - val_auc: 0.6540\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1290 - auc: 0.6961 - val_loss: 2.0162 - val_auc: 0.7511\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.2418 - auc: 0.6786 - val_loss: 1.8923 - val_auc: 0.8028\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.7792 - auc: 0.6891 - val_loss: 1.6586 - val_auc: 0.7564\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.9340 - auc: 0.7453 - val_loss: 1.5280 - val_auc: 0.5469\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7963 - auc: 0.7030 - val_loss: 1.4282 - val_auc: 0.7608\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.7590 - auc: 0.7138 - val_loss: 1.1646 - val_auc: 0.7647\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.0484 - auc: 0.7028 - val_loss: 1.9987 - val_auc: 0.6618\n",
      "Wall time: 17.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Valor Predictivo Positivo</th>\n",
       "      <th>Valor Predictivo Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.795193</td>\n",
       "      <td>0.850416</td>\n",
       "      <td>0.549223</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.779188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validacion</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.808824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Set   AUC ROC  Especificidad  Sensibilidad  \\\n",
       "0       Train  0.795193       0.850416      0.549223   \n",
       "1  Validacion  0.838235       0.859375      0.617647   \n",
       "\n",
       "   Valor Predictivo Positivo  Valor Predictivo Negativo  \n",
       "0                     0.6625                   0.779188  \n",
       "1                     0.7000                   0.808824  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "name = 'Adam'\n",
    "checkdir = join(checkpoints_path, name)\n",
    "tensordir = join(tensor_path, name)\n",
    "tensor_call = TensorBoard(log_dir=tensordir)\n",
    "adam_checkpoint_callback = ModelCheckpoint(filepath=checkdir,\n",
    "                                                  save_weights_only=True,\n",
    "                                                  monitor='val_auc',\n",
    "                                                  mode='max',\n",
    "                                                  save_best_only=True)\n",
    "\n",
    "adam_model = Sequential()\n",
    "adam_model.add(Dense(units=1, activation='sigmoid', input_shape=(x_train_norm.shape[1],)))\n",
    "adam_model.compile(optimizer=Adam(learning_rate=4.7), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "history = adam_model.fit(x_train_norm, y_train, epochs=100, validation_data=(x_valid_norm, y_valid), callbacks=[adam_checkpoint_callback, tensor_call], \n",
    "                          verbose=1)\n",
    "# Cargo el mejor modelo entrenado\n",
    "adam_model.load_weights(checkdir)\n",
    "verify_model(adam_model, x_train_norm, y_train, x_valid_norm, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390cd47c-0644-4132-9406-8a01618ab605",
   "metadata": {},
   "source": [
    "Evaluaci√≥n contra test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa6b96dc-eef3-44da-94ea-4e2adbaadc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando SGD\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Valor Predictivo Positivo</th>\n",
       "      <th>Valor Predictivo Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.811850</td>\n",
       "      <td>0.817175</td>\n",
       "      <td>0.626943</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.803815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.832846</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Set   AUC ROC  Especificidad  Sensibilidad  Valor Predictivo Positivo  \\\n",
       "0  Train  0.811850       0.817175      0.626943                   0.647059   \n",
       "1   Test  0.832846       0.840000      0.707317                   0.707317   \n",
       "\n",
       "   Valor Predictivo Negativo  \n",
       "0                   0.803815  \n",
       "1                   0.840000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Utilizando SGD')\n",
    "verify_model(mom_model, x_train_norm, y_train, x_test_norm, y_test, valid_label='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac180cd5-9198-494f-b8fc-7aecc001cd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando Adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Valor Predictivo Positivo</th>\n",
       "      <th>Valor Predictivo Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.795193</td>\n",
       "      <td>0.850416</td>\n",
       "      <td>0.549223</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.779188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.830894</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Set   AUC ROC  Especificidad  Sensibilidad  Valor Predictivo Positivo  \\\n",
       "0  Train  0.795193       0.850416      0.549223                     0.6625   \n",
       "1   Test  0.830894       0.826667      0.658537                     0.6750   \n",
       "\n",
       "   Valor Predictivo Negativo  \n",
       "0                   0.779188  \n",
       "1                   0.815789  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Utilizando Adam')\n",
    "verify_model(adam_model, x_train_norm, y_train, x_test_norm, y_test, valid_label='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31e8a4-7a64-4adc-83f2-37ec8d28c05e",
   "metadata": {},
   "source": [
    "Finalmente se obtiene que el modelo que utiliza como optimizador SGD y los hyperpar√°metros optimizados fue el mejor de los entrenados hasta ahora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd1e69-6207-4ce5-a9dd-6f2e48c04b0f",
   "metadata": {},
   "source": [
    "Cabe destacar una particularidad, que los resustados en Test son mejores que en el set de validacion, e incluso mejores que el set de train, con lo cual concluir que la metrica de nuestro modelo es AUC=0.86 no ser√≠a correcto, ya que es el caso en el que tenemos un estimador con alta varianza, por lo tanto una estimaci√≥n utilizando k-folding ser√≠a mas adecuada (si hay tiempo la hago...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "286270a0-46e5-4df1-b618-33749f075e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2_threshold_b(my_model, x_train, y_train, x_validation, y_validation):\n",
    "    y_train_pred = my_model.predict(x_train)\n",
    "    y_valid_pred = my_model.predict(x_validation)\n",
    "    th = np.linspace(0, 1, 100)\n",
    "    f2score_v = []\n",
    "    f2score_t = []\n",
    "    max_f = [0, 0]\n",
    "    for t in th:\n",
    "        y_pred_t = (y_train_pred > t).astype(int)\n",
    "        y_pred_v = (y_valid_pred > t).astype(int)\n",
    "        score_t = fbeta_score(y_train, y_pred_t, beta=2)\n",
    "        score_v = fbeta_score(y_validation, y_pred_v, beta=2)\n",
    "        f2score_t.append(score_t)\n",
    "        f2score_v.append(score_v)\n",
    "        if score_v > max_f[0]:\n",
    "            max_f[0] = score_v\n",
    "            max_f[1] = t\n",
    "    \n",
    "    print('Best threshold : {}'.format(max_f[1]))\n",
    "    plt.plot(th, f2score_t, label='train')\n",
    "    plt.plot(th, f2score_v, label='valid')\n",
    "    \n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('F2 score')\n",
    "    \n",
    "    plt.axvline(max_f[1], color='black', linestyle='--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1])\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0452c23-fd41-44f2-90fa-20a2646327be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold : 0.12121212121212122\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f2_threshold_b(mom_model, x_train_norm, y_train, x_valid_norm, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dd3b1d-d8ab-4955-bc23-f61a71ec4d33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
