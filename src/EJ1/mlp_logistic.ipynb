{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eadad356-bc8b-4ae3-af46-51624e9b6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from os.path import join\n",
    "from os import getcwd\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0664c46-861a-429d-a736-14b3d54276ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, auc\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e9ea86-22bd-4c88-8937-c34f49ce6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, clone_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.metrics import AUC # Area under the curve, default: ROC\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.initializers import GlorotNormal\n",
    "from keras.regularizers import l1, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fec708f-306d-4a12-9d9f-7f8020bb3544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4822c966-b64f-4ca0-9604-c9cd4b875624",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = getcwd()+'\\\\checkpoints_C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a024e19-bfc5-45b0-b492-e57323f6183f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../databases/diabetes.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "708d29ba-8b33-4740-909e-654070c43da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlayers = {\n",
    "    'BloodPressure': (40, np.Inf),\n",
    "    'SkinThickness': (0, 80),\n",
    "    'Insulin': (0, 400),\n",
    "    'BMI': (0, 50)\n",
    "}\n",
    "\n",
    "zeros = [\n",
    "    'Glucose',\n",
    "    'BloodPressure',\n",
    "    'SkinThickness',\n",
    "    'Insulin',\n",
    "    'BMI'\n",
    "]\n",
    "x_df = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    "y_df = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "077675fa-81fe-4dad-b1a2-af4a9384cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_changing_state(x_dataset, y_dataset, model, state, direction, my_callbacks):\n",
    "    # Split dataset into 15% test, 85% train \n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_df, y_df, test_size=0.15, random_state=state)\n",
    "    # Reemplazo los valores nulos y los outlayer\n",
    "    x_train_clean, _data = replace_outliers_zeros(x_train, outlayers, zeros, mean_median=True)\n",
    "    x_valid_clean, _data = replace_outliers_zeros(x_valid, outlayers, zeros, mean_median=True, data_to_replace=_data)\n",
    "    # Normalizo los datasets\n",
    "    x_train_norm, _norm_dict = normalize(x_train_clean, None)\n",
    "    x_valid_norm, _norm_dict = normalize(x_valid_clean, _norm_dict)\n",
    "    # Train model\n",
    "    history_mlp_0 = mlp_model.fit(x_train_norm, y_train, validation_data=(x_valid_norm, y_valid),\n",
    "                              batch_size=32, epochs=200,\n",
    "                              verbose=0, callbacks=my_callbacks) \n",
    "    # Cargo el mejor modelo entrenado\n",
    "    mlp_model.load_weights(direction)\n",
    "    results = verify_model(mlp_model, x_train_norm, y_train, x_valid_norm, y_valid)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bab0fcf-e5f0-4578-a471-b4de4003fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into 15% test, 85% train \n",
    "x_temp, x_test, y_temp, y_test = train_test_split(x_df, y_df, test_size=0.15)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_temp, y_temp, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1928f7a-ec8c-45e1-b11f-ff653b4ab78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazo los valores nulos y los outlayer\n",
    "x_train_clean, _data = replace_outliers_zeros(x_train, outlayers, zeros, mean_median=True)\n",
    "x_test_clean, _data = replace_outliers_zeros(x_test, outlayers, zeros, mean_median=True, data_to_replace=_data)\n",
    "x_valid_clean, _data = replace_outliers_zeros(x_valid, outlayers, zeros, mean_median=True, data_to_replace=_data)\n",
    "# Normalizo los datasets\n",
    "x_train_norm, _norm_dict = normalize(x_train_clean, None)\n",
    "x_valid_norm, _norm_dict = normalize(x_valid_clean, _norm_dict)\n",
    "x_test_norm, _norm_dict = normalize(x_test_clean, _norm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffc8e915-c772-4560-a6f5-434ecee7a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = EarlyStopping(monitor='val_auc', patience=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319ce718-b28b-4d57-a0d7-3a99e8d02098",
   "metadata": {},
   "source": [
    "### Definici√≥n de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0135178c-9c0a-44c1-b1dc-4a3bfbd2f8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mlp_0\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_0_checkpoint_callback = ModelCheckpoint(filepath=join(checkpoints_path, 'mlp_0'), save_weights_only=True, monitor='val_auc', mode='max', \n",
    "                                           save_best_only=True)\n",
    "mlp_model = Sequential(name='mlp_0')\n",
    "\n",
    "mlp_model.add(Dense(10, activation='relu', input_shape=(x_train_norm.shape[1],)))\n",
    "mlp_model.add(Dense(5, activation='linear'))\n",
    "mlp_model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.25)))\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5efacb4-e902-4b98-8aca-42089e2a1053",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.compile(optimizer=Adam(learning_rate=0.02), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c4e0371-ae2c-4392-9e57-c3ec22564c62",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.9992 - auc: 0.7221 - val_loss: 0.7284 - val_auc: 0.8045\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6302 - auc: 0.8223 - val_loss: 0.5678 - val_auc: 0.8050\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5254 - auc: 0.8332 - val_loss: 0.5214 - val_auc: 0.8069\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - auc: 0.8374 - val_loss: 0.5117 - val_auc: 0.8060\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4899 - auc: 0.8399 - val_loss: 0.5062 - val_auc: 0.8031\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - auc: 0.8414 - val_loss: 0.5050 - val_auc: 0.8009\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - auc: 0.8387 - val_loss: 0.5006 - val_auc: 0.8057\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4716 - auc: 0.8503 - val_loss: 0.5061 - val_auc: 0.8103\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - auc: 0.8480 - val_loss: 0.5072 - val_auc: 0.8062\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - auc: 0.8500 - val_loss: 0.5000 - val_auc: 0.8033\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - auc: 0.8500 - val_loss: 0.5076 - val_auc: 0.8045\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - auc: 0.8544 - val_loss: 0.5003 - val_auc: 0.8031\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - auc: 0.8581 - val_loss: 0.5027 - val_auc: 0.8093\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8563 - val_loss: 0.5078 - val_auc: 0.8007\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - auc: 0.8590 - val_loss: 0.5093 - val_auc: 0.8069\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - auc: 0.8626 - val_loss: 0.5029 - val_auc: 0.8091\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4474 - auc: 0.8659 - val_loss: 0.5098 - val_auc: 0.8089\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - auc: 0.8621 - val_loss: 0.5084 - val_auc: 0.8093\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - auc: 0.8640 - val_loss: 0.5221 - val_auc: 0.8024\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4501 - auc: 0.8648 - val_loss: 0.5091 - val_auc: 0.8026\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - auc: 0.8691 - val_loss: 0.5143 - val_auc: 0.8038\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - auc: 0.8679 - val_loss: 0.5083 - val_auc: 0.8072\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - auc: 0.8634 - val_loss: 0.5126 - val_auc: 0.8038\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - auc: 0.8708 - val_loss: 0.5185 - val_auc: 0.8014\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - auc: 0.8722 - val_loss: 0.5198 - val_auc: 0.8004\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - auc: 0.8775 - val_loss: 0.5207 - val_auc: 0.8055\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - auc: 0.8763 - val_loss: 0.5086 - val_auc: 0.8043\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - auc: 0.8757 - val_loss: 0.5190 - val_auc: 0.8014\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - auc: 0.8763 - val_loss: 0.5157 - val_auc: 0.8050\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - auc: 0.8779 - val_loss: 0.5204 - val_auc: 0.7987\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - auc: 0.8816 - val_loss: 0.5517 - val_auc: 0.7985\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - auc: 0.8789 - val_loss: 0.5195 - val_auc: 0.7995\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - auc: 0.8761 - val_loss: 0.5159 - val_auc: 0.8021\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - auc: 0.8800 - val_loss: 0.5625 - val_auc: 0.8014\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - auc: 0.8796 - val_loss: 0.5271 - val_auc: 0.7896\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - auc: 0.8811 - val_loss: 0.5305 - val_auc: 0.7983\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - auc: 0.8847 - val_loss: 0.5208 - val_auc: 0.8067\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - auc: 0.8820 - val_loss: 0.5296 - val_auc: 0.7949\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - auc: 0.8777 - val_loss: 0.5307 - val_auc: 0.8002\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4175 - auc: 0.8848 - val_loss: 0.5236 - val_auc: 0.7966\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - auc: 0.8840 - val_loss: 0.5364 - val_auc: 0.8004\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - auc: 0.8802 - val_loss: 0.5169 - val_auc: 0.8069\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - auc: 0.8830 - val_loss: 0.5318 - val_auc: 0.7983\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - auc: 0.8840 - val_loss: 0.5176 - val_auc: 0.7939\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - auc: 0.8859 - val_loss: 0.5335 - val_auc: 0.7975\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - auc: 0.8874 - val_loss: 0.5182 - val_auc: 0.8069\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4123 - auc: 0.8872 - val_loss: 0.5415 - val_auc: 0.8021\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - auc: 0.8870 - val_loss: 0.5241 - val_auc: 0.8021\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - auc: 0.8843 - val_loss: 0.5357 - val_auc: 0.8055\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - auc: 0.8861 - val_loss: 0.5781 - val_auc: 0.8052\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - auc: 0.8789 - val_loss: 0.5346 - val_auc: 0.8048\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - auc: 0.8880 - val_loss: 0.5295 - val_auc: 0.7992\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - auc: 0.8852 - val_loss: 0.5696 - val_auc: 0.7997\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4153 - auc: 0.8885 - val_loss: 0.5326 - val_auc: 0.8130\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4072 - auc: 0.8911 - val_loss: 0.5168 - val_auc: 0.8170\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4089 - auc: 0.8892 - val_loss: 0.5299 - val_auc: 0.8110\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4023 - auc: 0.8959 - val_loss: 0.5379 - val_auc: 0.8101\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4012 - auc: 0.8957 - val_loss: 0.5351 - val_auc: 0.8151\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4067 - auc: 0.8919 - val_loss: 0.5165 - val_auc: 0.8214\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4036 - auc: 0.8932 - val_loss: 0.5248 - val_auc: 0.8125\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3973 - auc: 0.8974 - val_loss: 0.5692 - val_auc: 0.8062\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3973 - auc: 0.8976 - val_loss: 0.5325 - val_auc: 0.8002\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3988 - auc: 0.8972 - val_loss: 0.5432 - val_auc: 0.8069\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3966 - auc: 0.8984 - val_loss: 0.5410 - val_auc: 0.8069\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3959 - auc: 0.8987 - val_loss: 0.5361 - val_auc: 0.8028\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3956 - auc: 0.8977 - val_loss: 0.5271 - val_auc: 0.8108\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3948 - auc: 0.8991 - val_loss: 0.5519 - val_auc: 0.8093\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3922 - auc: 0.9007 - val_loss: 0.5526 - val_auc: 0.7966\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3917 - auc: 0.9010 - val_loss: 0.5384 - val_auc: 0.8031\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3931 - auc: 0.8993 - val_loss: 0.5661 - val_auc: 0.8024\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3897 - auc: 0.9028 - val_loss: 0.5762 - val_auc: 0.7985\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3914 - auc: 0.9007 - val_loss: 0.5448 - val_auc: 0.7930\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3878 - auc: 0.9025 - val_loss: 0.6057 - val_auc: 0.7995\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3911 - auc: 0.9010 - val_loss: 0.5473 - val_auc: 0.8009\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3887 - auc: 0.9028 - val_loss: 0.5543 - val_auc: 0.7947\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3863 - auc: 0.9018 - val_loss: 0.5517 - val_auc: 0.7927\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3998 - auc: 0.9001 - val_loss: 0.5706 - val_auc: 0.7997\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4043 - auc: 0.8947 - val_loss: 0.5597 - val_auc: 0.7903\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3918 - auc: 0.9007 - val_loss: 0.5623 - val_auc: 0.7913\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3835 - auc: 0.9045 - val_loss: 0.5868 - val_auc: 0.7963\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3814 - auc: 0.9058 - val_loss: 0.5598 - val_auc: 0.7915\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3812 - auc: 0.9057 - val_loss: 0.6013 - val_auc: 0.7925\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3869 - auc: 0.9034 - val_loss: 0.5635 - val_auc: 0.7898\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3805 - auc: 0.9078 - val_loss: 0.5624 - val_auc: 0.7932\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3880 - auc: 0.9025 - val_loss: 0.6288 - val_auc: 0.7939\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3801 - auc: 0.9072 - val_loss: 0.5754 - val_auc: 0.7848\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3831 - auc: 0.9060 - val_loss: 0.5828 - val_auc: 0.7867\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3803 - auc: 0.9082 - val_loss: 0.5879 - val_auc: 0.7894\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3768 - auc: 0.9079 - val_loss: 0.5808 - val_auc: 0.7901\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3766 - auc: 0.9084 - val_loss: 0.6011 - val_auc: 0.7879\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3759 - auc: 0.9089 - val_loss: 0.5828 - val_auc: 0.7802\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3755 - auc: 0.9083 - val_loss: 0.5816 - val_auc: 0.7862\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3764 - auc: 0.9086 - val_loss: 0.5963 - val_auc: 0.7833\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3884 - auc: 0.9025 - val_loss: 0.5827 - val_auc: 0.7742\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3808 - auc: 0.9064 - val_loss: 0.6073 - val_auc: 0.7773\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3754 - auc: 0.9088 - val_loss: 0.6281 - val_auc: 0.7860\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3713 - auc: 0.9109 - val_loss: 0.6163 - val_auc: 0.7833\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3826 - auc: 0.9076 - val_loss: 0.5984 - val_auc: 0.7841\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3789 - auc: 0.9073 - val_loss: 0.6307 - val_auc: 0.7824\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3737 - auc: 0.9103 - val_loss: 0.5814 - val_auc: 0.7853\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3695 - auc: 0.9129 - val_loss: 0.6398 - val_auc: 0.7922\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3783 - auc: 0.9087 - val_loss: 0.5637 - val_auc: 0.7756\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3695 - auc: 0.9143 - val_loss: 0.6836 - val_auc: 0.7836\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3775 - auc: 0.9098 - val_loss: 0.6453 - val_auc: 0.7703\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3738 - auc: 0.9112 - val_loss: 0.6247 - val_auc: 0.7718\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3678 - auc: 0.9130 - val_loss: 0.6395 - val_auc: 0.7783\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3677 - auc: 0.9134 - val_loss: 0.6059 - val_auc: 0.7742\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3731 - auc: 0.9124 - val_loss: 0.6792 - val_auc: 0.7595\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3736 - auc: 0.9137 - val_loss: 0.7079 - val_auc: 0.7744\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3770 - auc: 0.9082 - val_loss: 0.6036 - val_auc: 0.7759\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3697 - auc: 0.9116 - val_loss: 0.6519 - val_auc: 0.7619\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3742 - auc: 0.9104 - val_loss: 0.6420 - val_auc: 0.7687\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3645 - auc: 0.9148 - val_loss: 0.6344 - val_auc: 0.7650\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3719 - auc: 0.9119 - val_loss: 0.6116 - val_auc: 0.7458\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3710 - auc: 0.9134 - val_loss: 0.7619 - val_auc: 0.7578\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3664 - auc: 0.9140 - val_loss: 0.6589 - val_auc: 0.7588\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3662 - auc: 0.9146 - val_loss: 0.6270 - val_auc: 0.7578\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3623 - auc: 0.9158 - val_loss: 0.7003 - val_auc: 0.7597\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3646 - auc: 0.9144 - val_loss: 0.6775 - val_auc: 0.7482\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3621 - auc: 0.9154 - val_loss: 0.6740 - val_auc: 0.7429\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3666 - auc: 0.9131 - val_loss: 0.6513 - val_auc: 0.7518\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3576 - auc: 0.9203 - val_loss: 0.6742 - val_auc: 0.7518\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3670 - auc: 0.9178 - val_loss: 0.6698 - val_auc: 0.7518\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3642 - auc: 0.9161 - val_loss: 0.6416 - val_auc: 0.7537\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3640 - auc: 0.9162 - val_loss: 0.6647 - val_auc: 0.7540\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3617 - auc: 0.9159 - val_loss: 0.6463 - val_auc: 0.7492\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3627 - auc: 0.9179 - val_loss: 0.7175 - val_auc: 0.7446\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3765 - auc: 0.9150 - val_loss: 0.7644 - val_auc: 0.7487\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3710 - auc: 0.9131 - val_loss: 0.6681 - val_auc: 0.7434\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3576 - auc: 0.9189 - val_loss: 0.6713 - val_auc: 0.7448\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3578 - auc: 0.9180 - val_loss: 0.7235 - val_auc: 0.7388\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3655 - auc: 0.9167 - val_loss: 0.6790 - val_auc: 0.7513\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3626 - auc: 0.9166 - val_loss: 0.6711 - val_auc: 0.7496\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3595 - auc: 0.9188 - val_loss: 0.6827 - val_auc: 0.7583\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3588 - auc: 0.9181 - val_loss: 0.7783 - val_auc: 0.7468\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3621 - auc: 0.9202 - val_loss: 0.6087 - val_auc: 0.7398\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3649 - auc: 0.9142 - val_loss: 0.6982 - val_auc: 0.7494\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3571 - auc: 0.9195 - val_loss: 0.7508 - val_auc: 0.7436\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3602 - auc: 0.9164 - val_loss: 0.6756 - val_auc: 0.7506\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3513 - auc: 0.9219 - val_loss: 0.7496 - val_auc: 0.7405\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3549 - auc: 0.9219 - val_loss: 0.6385 - val_auc: 0.7419\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3572 - auc: 0.9201 - val_loss: 0.7704 - val_auc: 0.7460\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3562 - auc: 0.9190 - val_loss: 0.6695 - val_auc: 0.7369\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3561 - auc: 0.9181 - val_loss: 0.6869 - val_auc: 0.7475\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3572 - auc: 0.9182 - val_loss: 0.6641 - val_auc: 0.7388\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3678 - auc: 0.9153 - val_loss: 0.7553 - val_auc: 0.7443\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3617 - auc: 0.9162 - val_loss: 0.7601 - val_auc: 0.7436\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3580 - auc: 0.9180 - val_loss: 0.7667 - val_auc: 0.7381\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3608 - auc: 0.9193 - val_loss: 0.6468 - val_auc: 0.7354\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3725 - auc: 0.9127 - val_loss: 0.7725 - val_auc: 0.7494\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3538 - auc: 0.9197 - val_loss: 0.6919 - val_auc: 0.7407\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3527 - auc: 0.9193 - val_loss: 0.6886 - val_auc: 0.7419\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3687 - auc: 0.9124 - val_loss: 0.7599 - val_auc: 0.7395\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3570 - auc: 0.9185 - val_loss: 0.7717 - val_auc: 0.7374\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3533 - auc: 0.9202 - val_loss: 0.6616 - val_auc: 0.7376\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3478 - auc: 0.9224 - val_loss: 0.7602 - val_auc: 0.7350\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3541 - auc: 0.9209 - val_loss: 0.6917 - val_auc: 0.7330\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3618 - auc: 0.9150 - val_loss: 0.6919 - val_auc: 0.7335\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3521 - auc: 0.9218 - val_loss: 0.7784 - val_auc: 0.7427\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3510 - auc: 0.9203 - val_loss: 0.6663 - val_auc: 0.7374\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3480 - auc: 0.9219 - val_loss: 0.8131 - val_auc: 0.7369\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3573 - auc: 0.9197 - val_loss: 0.6168 - val_auc: 0.7309\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3489 - auc: 0.9212 - val_loss: 0.8186 - val_auc: 0.7350\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3491 - auc: 0.9214 - val_loss: 0.6958 - val_auc: 0.7381\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3456 - auc: 0.9236 - val_loss: 0.7938 - val_auc: 0.7350\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3484 - auc: 0.9218 - val_loss: 0.7059 - val_auc: 0.7362\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3559 - auc: 0.9192 - val_loss: 0.7130 - val_auc: 0.7393\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3612 - auc: 0.9170 - val_loss: 0.7728 - val_auc: 0.7364\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3674 - auc: 0.9112 - val_loss: 0.7706 - val_auc: 0.7277\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3483 - auc: 0.9216 - val_loss: 0.7610 - val_auc: 0.7318\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3493 - auc: 0.9210 - val_loss: 0.7182 - val_auc: 0.7390\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3474 - auc: 0.9223 - val_loss: 0.7243 - val_auc: 0.7376\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3448 - auc: 0.9244 - val_loss: 0.7027 - val_auc: 0.7330\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3465 - auc: 0.9221 - val_loss: 0.6734 - val_auc: 0.7386\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3425 - auc: 0.9236 - val_loss: 0.7763 - val_auc: 0.7364\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3557 - auc: 0.9203 - val_loss: 0.6159 - val_auc: 0.7410\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3590 - auc: 0.9169 - val_loss: 0.7305 - val_auc: 0.7381\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3523 - auc: 0.9199 - val_loss: 0.6376 - val_auc: 0.7494\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3465 - auc: 0.9231 - val_loss: 0.7614 - val_auc: 0.7400\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3496 - auc: 0.9218 - val_loss: 0.6573 - val_auc: 0.7333\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3537 - auc: 0.9213 - val_loss: 0.7001 - val_auc: 0.7458\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3551 - auc: 0.9185 - val_loss: 0.7643 - val_auc: 0.7448\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3596 - auc: 0.9166 - val_loss: 0.6740 - val_auc: 0.7482\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3467 - auc: 0.9220 - val_loss: 0.7549 - val_auc: 0.7446\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3449 - auc: 0.9226 - val_loss: 0.7279 - val_auc: 0.7393\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3458 - auc: 0.9240 - val_loss: 0.7481 - val_auc: 0.7463\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3483 - auc: 0.9198 - val_loss: 0.7675 - val_auc: 0.7412\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3428 - auc: 0.9243 - val_loss: 0.6587 - val_auc: 0.7400\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3545 - auc: 0.9205 - val_loss: 0.7384 - val_auc: 0.7359\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3451 - auc: 0.9234 - val_loss: 0.7156 - val_auc: 0.7357\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3405 - auc: 0.9247 - val_loss: 0.7484 - val_auc: 0.7313\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3445 - auc: 0.9226 - val_loss: 0.8059 - val_auc: 0.7369\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3420 - auc: 0.9252 - val_loss: 0.7790 - val_auc: 0.7277\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3495 - auc: 0.9223 - val_loss: 0.7199 - val_auc: 0.7383\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3419 - auc: 0.9242 - val_loss: 0.7259 - val_auc: 0.7345\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3477 - auc: 0.9217 - val_loss: 0.8738 - val_auc: 0.7287\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3438 - auc: 0.9234 - val_loss: 0.6765 - val_auc: 0.7412\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3418 - auc: 0.9245 - val_loss: 0.7590 - val_auc: 0.7371\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3479 - auc: 0.9211 - val_loss: 0.6776 - val_auc: 0.7395\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3436 - auc: 0.9232 - val_loss: 0.7549 - val_auc: 0.7422\n"
     ]
    }
   ],
   "source": [
    "history_mlp_0 = mlp_model.fit(x_train_norm, y_train, validation_data=(x_valid_norm, y_valid),\n",
    "                              batch_size=32, epochs=200,\n",
    "                              verbose=1, callbacks=[mlp_0_checkpoint_callback]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2468623-f729-4536-b0aa-0376dec4f190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Valor Predictivo Positivo</th>\n",
       "      <th>Valor Predictivo Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.900262</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.778894</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.872093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validacion</td>\n",
       "      <td>0.821377</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Set   AUC ROC  Especificidad  Sensibilidad  \\\n",
       "0       Train  0.900262       0.845070      0.778894   \n",
       "1  Validacion  0.821377       0.776119      0.741935   \n",
       "\n",
       "   Valor Predictivo Positivo  Valor Predictivo Negativo  \n",
       "0                   0.738095                   0.872093  \n",
       "1                   0.605263                   0.866667  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargo el mejor modelo entrenado\n",
    "mlp_model.load_weights(join(checkpoints_path, 'mlp_0'))\n",
    "verify_model(mlp_model, x_train_norm, y_train, x_valid_norm, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166d906e-cc88-413d-a538-acf90b7fc195",
   "metadata": {},
   "source": [
    "Salieron resultados interesantes, vamos a verificar si se mantiene al cambiar el random state al hacer split de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e491747-9265-4e72-9cbe-de10788cbfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mlp_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_state = Sequential(name='mlp_1')\n",
    "mlp_state.add(Dense(10, activation='relu', input_shape=(x_train_norm.shape[1],)))\n",
    "mlp_state.add(Dense(5, activation='linear'))\n",
    "mlp_state.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.25)))\n",
    "mlp_state.compile(optimizer=Adam(learning_rate=0.02), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "pesos_inicial = mlp_state.get_weights()\n",
    "mlp_state.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c79987f8-7c3f-4504-9e03-1bfed5c67d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runing state 0\n",
      "Runing state 1\n",
      "Runing state 2\n",
      "Runing state 3\n",
      "Runing state 4\n",
      "Runing state 5\n",
      "Runing state 6\n",
      "Runing state 7\n",
      "Runing state 8\n",
      "Runing state 9\n"
     ]
    }
   ],
   "source": [
    "train_auc = []\n",
    "valid_auc = []\n",
    "results = []\n",
    "\n",
    "for i in range(10):\n",
    "    print('Runing state', i)\n",
    "    name  = 'mlp_state_{}'.format(i)\n",
    "    mlp_state.set_weights(pesos_inicial)\n",
    "    checkdir = join(checkpoints_path, name)\n",
    "    temp_callback = ModelCheckpoint(filepath=checkdir, save_weights_only=True, monitor='val_auc', mode='max', save_best_only=True)\n",
    "    metrics = run_changing_state(x_temp, y_temp, mlp_state, i, checkdir, [temp_callback])\n",
    "    results.append(metrics)\n",
    "    train_auc.append(metrics['AUC ROC'][0])\n",
    "    valid_auc.append(metrics['AUC ROC'][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cdace0c-54bb-411b-93c1-4c1111d267d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_auc, label='Train')\n",
    "plt.plot(valid_auc, label='Validation')\n",
    "mean = np.mean(valid_auc)\n",
    "std = np.std(valid_auc)\n",
    "plt.hlines([mean+std, mean, mean-std], 0, 9)   \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dc3079-2d04-4d44-b345-c8a8be95bf84",
   "metadata": {},
   "source": [
    "Se puede observar que en la mayoria de los casos la metrica de validaci√≥n da mejor que la metrica de train, con lo cual se puede inferir que el modelo tendr√° una gran varianza debido a la poca cantidad de datos disponible para los par√°metros que requiere entrenar el modelo. Por lo tanto una mejor opcion es utilizar k-folding en lugar de hold out validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0901419e-6962-4b1b-9ed4-a1a2acfa0e54",
   "metadata": {},
   "source": [
    "Ahora vamos a probar utilizar 1 o 2 capas ocultas, variando la cantidad de neuronas entre 5, 10 y 30, modificando la activacion entre relu y lineal. Para ello utilizaremos la tecnica de k-folding y la metrica de cada set de hyperpar√°metros sera el promedio de las metricas de cada fold. Una vez testeado esto se continuara buscando mejorar el modelo cambiando la regularizacion o agregando capas de Droput o Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32deaee6-b847-4210-9f3d-944edec57fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folding = KFold(n_splits=5)\n",
    "\n",
    "def train_model(x_dataset, y_dataset, model, name, batch, stopping_patiece=None):\n",
    "    pesos_default = model.get_weights()\n",
    "    folds = folding.split(x_dataset)\n",
    "    auc_val = []\n",
    "    results = []\n",
    "    models = []\n",
    "    curr = 0\n",
    "    for train, valid in folds:\n",
    "        # Split dataset\n",
    "        x_train, x_valid = x_dataset.iloc[train], x_dataset.iloc[valid]\n",
    "        y_train, y_valid = y_dataset.iloc[train], y_dataset.iloc[valid]\n",
    "        \n",
    "        # Proceso los datos\n",
    "        x_train_c, _data = replace_outliers_zeros(x_train, outlayers, zeros, mean_median=True)\n",
    "        x_valid_c, _data = replace_outliers_zeros(x_valid, outlayers, zeros, mean_median=True, data_to_replace=_data)\n",
    "        # Normalizo los datasets\n",
    "        x_train_n, _norm_dict = normalize(x_train_c, None)\n",
    "        x_valid_n, _norm_dict = normalize(x_valid_c, _norm_dict)\n",
    "    \n",
    "        # Create callbacks\n",
    "        checkdir = join(checkpoints_path, name+'f{}'.format(curr))\n",
    "        temp_callback = ModelCheckpoint(filepath=checkdir, save_weights_only=True, monitor='val_auc', mode='max', save_best_only=True)\n",
    "        my_callbacks = [temp_callback]\n",
    "        if stopping_patiece:\n",
    "            my_callbacks.append(EarlyStopping(monitor='val_auc', patience=stopping_patiece))\n",
    "        # Train model\n",
    "        history = model.fit(x_train_n, y_train, validation_data=(x_valid_n, y_valid),\n",
    "                            batch_size=batch, epochs=200,\n",
    "                            verbose=0, callbacks=my_callbacks) \n",
    "        # Cargo el mejor modelo entrenado\n",
    "        model.load_weights(checkdir)\n",
    "        metrics = verify_model(model, x_train_n, y_train, x_valid_n, y_valid)\n",
    "        auc_val.append(metrics['AUC ROC'][1])\n",
    "        results.append(metrics)\n",
    "        # Reset model for next training\n",
    "        models.append(model.get_weights())\n",
    "        model.set_weights(pesos_default)\n",
    "        curr += 1\n",
    "    return np.mean(auc_val), results, models    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2080a7-310c-4822-8a1f-ed6c835c5dc3",
   "metadata": {},
   "source": [
    "1 capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "633e8759-b00f-4a5b-88c2-7606855946a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing -> n5_b32_linear\n",
      "Auc score =  0.8271272156197718\n",
      "Testing -> n5_b64_linear\n",
      "Auc score =  0.8273518002462643\n",
      "Testing -> n5_b32_relu\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "Auc score =  0.8304705854804466\n",
      "Testing -> n5_b64_relu\n",
      "Auc score =  0.8277850720497744\n",
      "Testing -> n10_b32_linear\n",
      "Auc score =  0.8284463108227241\n",
      "Testing -> n10_b64_linear\n",
      "Auc score =  0.8291442805705407\n",
      "Testing -> n10_b32_relu\n",
      "Auc score =  0.8311581125491634\n",
      "Testing -> n10_b64_relu\n",
      "Auc score =  0.8294404239203811\n",
      "Testing -> n30_b32_linear\n",
      "Auc score =  0.8282706327840765\n",
      "Testing -> n30_b64_linear\n",
      "Auc score =  0.829951175973485\n",
      "Testing -> n30_b32_relu\n",
      "Auc score =  0.8332847924711487\n",
      "Testing -> n30_b64_relu\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0101s). Check your callbacks.\n",
      "Auc score =  0.8321394820768198\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for neuronas in [5, 10, 30]:\n",
    "    for activation in ['linear', 'relu']:\n",
    "        for batch in [32, 64]:\n",
    "            name = 'n{}_b{}_{}'.format(neuronas, batch, activation)\n",
    "            print('Testing ->', name)\n",
    "            # Armo el modelo\n",
    "            test_model = Sequential(name=name)\n",
    "            test_model.add(Dense(neuronas, activation=activation, input_shape=(x_temp.shape[1],)))\n",
    "            test_model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.25)))\n",
    "            # Compilo el modelo\n",
    "            test_model.compile(optimizer=Adam(learning_rate=0.02), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "            auc, metrics, _ = train_model(x_temp, y_temp, test_model, name, batch, stopping_patiece=50)\n",
    "            results[name] = (auc, metrics)\n",
    "            print('Auc score = ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b522c119-5a74-4aaf-b315-63453017dd68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing -> na5_nb5_b32_linear\n",
      "Testing -> na5_nb5_b64_linear\n",
      "Testing -> na5_nb5_b32_relu\n",
      "Testing -> na5_nb5_b64_relu\n",
      "Testing -> na5_nb10_b32_linear\n",
      "Testing -> na5_nb10_b64_linear\n",
      "Testing -> na5_nb10_b32_relu\n",
      "Testing -> na5_nb10_b64_relu\n",
      "Testing -> na5_nb30_b32_linear\n",
      "Testing -> na5_nb30_b64_linear\n",
      "Testing -> na5_nb30_b32_relu\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0080s). Check your callbacks.\n",
      "Testing -> na5_nb30_b64_relu\n",
      "Testing -> na10_nb5_b32_linear\n",
      "Testing -> na10_nb5_b64_linear\n",
      "Testing -> na10_nb5_b32_relu\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0005s). Check your callbacks.\n",
      "Testing -> na10_nb5_b64_relu\n",
      "Testing -> na10_nb10_b32_linear\n",
      "Testing -> na10_nb10_b64_linear\n",
      "Testing -> na10_nb10_b32_relu\n",
      "Testing -> na10_nb10_b64_relu\n",
      "Testing -> na10_nb30_b32_linear\n",
      "Testing -> na10_nb30_b64_linear\n",
      "Testing -> na10_nb30_b32_relu\n",
      "Testing -> na10_nb30_b64_relu\n",
      "Testing -> na30_nb5_b32_linear\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0020s). Check your callbacks.\n",
      "Testing -> na30_nb5_b64_linear\n",
      "Testing -> na30_nb5_b32_relu\n",
      "Testing -> na30_nb5_b64_relu\n",
      "Testing -> na30_nb10_b32_linear\n",
      "Testing -> na30_nb10_b64_linear\n",
      "Testing -> na30_nb10_b32_relu\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0100s). Check your callbacks.\n",
      "Testing -> na30_nb10_b64_relu\n",
      "Testing -> na30_nb30_b32_linear\n",
      "Testing -> na30_nb30_b64_linear\n",
      "Testing -> na30_nb30_b32_relu\n",
      "Testing -> na30_nb30_b64_relu\n"
     ]
    }
   ],
   "source": [
    "for neuronas_1 in [5, 10, 30]:\n",
    "    for neuronas_2 in [5, 10, 30]:\n",
    "        for activation in ['linear', 'relu']:\n",
    "            for batch in [32, 64]:\n",
    "                name = 'na{}_nb{}_b{}_{}'.format(neuronas_1, neuronas_2, batch, activation)\n",
    "                print('Testing ->', name)\n",
    "                # Armo el modelo\n",
    "                test_model = Sequential(name=name)\n",
    "                test_model.add(Dense(neuronas_1, activation=activation, input_shape=(x_temp.shape[1],)))\n",
    "                test_model.add(Dense(neuronas_2, activation=activation))\n",
    "                test_model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.25)))\n",
    "                # Compilo el modelo\n",
    "                test_model.compile(optimizer=Adam(learning_rate=0.02), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "                auc, metrics, _ = train_model(x_temp, y_temp, test_model, name, batch, stopping_patiece=50)\n",
    "                results[name] = (auc, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe383c-2854-4ae0-8838-738747eedd59",
   "metadata": {},
   "source": [
    "Veo los 10 mejores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91b488f9-fcef-4761-b17c-a38956166f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na30_nb10_b64_relu -> 0.8446188136825024\n",
      "na30_nb5_b32_relu -> 0.8418219204257831\n",
      "na10_nb10_b64_relu -> 0.840528520785529\n",
      "na30_nb30_b64_relu -> 0.8400677436723178\n",
      "na30_nb10_b32_relu -> 0.8390895928721971\n",
      "na10_nb5_b32_relu -> 0.8383933985619716\n",
      "na5_nb5_b32_relu -> 0.8370869007082261\n",
      "na30_nb5_b64_relu -> 0.8368245883944976\n",
      "na10_nb5_b64_relu -> 0.835652844583813\n",
      "na10_nb30_b32_relu -> 0.8346699915204978\n"
     ]
    }
   ],
   "source": [
    "sorted_results = list(reversed(sorted(results.items(), key=lambda x: x[1][0])))\n",
    "for i in sorted_results[0:10]:\n",
    "    print(i[0], '->', i[1][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c6fbf-5ebd-4482-84d8-8760d599e0e5",
   "metadata": {},
   "source": [
    "Se puede observar como los de mejor performance son en su mayoria redes con 2 capas ocultas, y con gran cantidad de neuronas en cada una. Con estos resultados se buscara optimizar los hyperpar√°metros de los 3 mejores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26a31e61-2ea6-4415-807f-312dd67f09ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing -> na30_nb10_b32_relu_relu_d0\n",
      "Testing -> na30_nb10_b32_relu_relu_d1\n",
      "Testing -> na30_nb10_b64_relu_relu_d0\n",
      "Testing -> na30_nb10_b64_relu_relu_d1\n",
      "Testing -> na30_nb10_b32_relu_linear_d0\n",
      "Testing -> na30_nb10_b32_relu_linear_d1\n",
      "Testing -> na30_nb10_b64_relu_linear_d0\n",
      "Testing -> na30_nb10_b64_relu_linear_d1\n",
      "Testing -> na30_nb10_b32_linear_relu_d0\n",
      "Testing -> na30_nb10_b32_linear_relu_d1\n",
      "Testing -> na30_nb10_b64_linear_relu_d0\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0005s). Check your callbacks.\n",
      "Testing -> na30_nb10_b64_linear_relu_d1\n",
      "Testing -> na30_nb10_b32_linear_linear_d0\n",
      "Testing -> na30_nb10_b32_linear_linear_d1\n",
      "Testing -> na30_nb10_b64_linear_linear_d0\n",
      "Testing -> na30_nb10_b64_linear_linear_d1\n",
      "Testing -> na30_nb30_b32_relu_relu_d0\n",
      "Testing -> na30_nb30_b32_relu_relu_d1\n",
      "Testing -> na30_nb30_b64_relu_relu_d0\n",
      "Testing -> na30_nb30_b64_relu_relu_d1\n",
      "Testing -> na30_nb30_b32_relu_linear_d0\n",
      "Testing -> na30_nb30_b32_relu_linear_d1\n",
      "Testing -> na30_nb30_b64_relu_linear_d0\n",
      "Testing -> na30_nb30_b64_relu_linear_d1\n",
      "Testing -> na30_nb30_b32_linear_relu_d0\n",
      "Testing -> na30_nb30_b32_linear_relu_d1\n",
      "Testing -> na30_nb30_b64_linear_relu_d0\n",
      "Testing -> na30_nb30_b64_linear_relu_d1\n",
      "Testing -> na30_nb30_b32_linear_linear_d0\n",
      "Testing -> na30_nb30_b32_linear_linear_d1\n",
      "Testing -> na30_nb30_b64_linear_linear_d0\n",
      "Testing -> na30_nb30_b64_linear_linear_d1\n",
      "na30_nb30_b32_linear_relu_d0 -> 0.8458163735469691\n",
      "na30_nb10_b32_linear_relu_d0 -> 0.8449458314239608\n",
      "na30_nb30_b32_linear_relu_d1 -> 0.8442588336745335\n",
      "na30_nb10_b32_relu_relu_d0 -> 0.8431166211755213\n",
      "na30_nb10_b32_relu_linear_d1 -> 0.8427230263109177\n",
      "na30_nb10_b32_linear_relu_d1 -> 0.8422756720583129\n",
      "na30_nb30_b64_linear_relu_d0 -> 0.8422149243524611\n",
      "na30_nb10_b64_relu_relu_d0 -> 0.8420672071061279\n",
      "na30_nb30_b64_linear_relu_d1 -> 0.8418188089452681\n",
      "na30_nb10_b64_relu_linear_d0 -> 0.8406175363712342\n"
     ]
    }
   ],
   "source": [
    "results_2 = {}\n",
    "neurona_1 = 30\n",
    "for neurona_2 in [10, 30]:\n",
    "    for act_n1 in ['relu', 'linear']:\n",
    "        for act_n2 in ['relu', 'linear']:\n",
    "            for batch in [32, 64]:\n",
    "                for drop in [0, 1]:\n",
    "                    name = 'na{}_nb{}_b{}_{}_{}_d{}'.format(neurona_1, neurona_2, batch, act_n1, act_n2, drop)\n",
    "                    print('Testing ->', name)\n",
    "                    # Armo el modelo\n",
    "                    test_model = Sequential(name=name)\n",
    "\n",
    "                    test_model.add(Dense(neurona_1, activation=act_n1, input_shape=(x_temp.shape[1],)))\n",
    "                    if drop:\n",
    "                        test_model.add(Dropout(rate=0.2))\n",
    "                    test_model.add(Dense(neurona_2, activation=act_n2))\n",
    "\n",
    "                    test_model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.25)))\n",
    "                    # Compilo el modelo\n",
    "                    test_model.compile(optimizer=Adam(learning_rate=0.02), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "                    auc, metrics, _ = train_model(x_temp, y_temp, test_model, name, batch, stopping_patiece=50)\n",
    "                    results_2[name] = (auc, metrics)\n",
    "                \n",
    "sorted_results_2 = list(reversed(sorted(results_2.items(), key=lambda x: x[1][0])))\n",
    "for i in sorted_results_2[0:10]:\n",
    "    print(i[0], '->', i[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "810969db-cbe4-435b-ba8d-437521ea3ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na30_nb30_b32_linear_relu_d1_b -> 0.8476227031995652\n",
      "na30_nb30_b32_linear_relu_d0_b -> 0.8428164488902864\n",
      "na30_nb10_b64_relu_linear_d0_b -> 0.8414353281274268\n",
      "na30_nb10_b64_relu_linear_d1_b -> 0.838907675546228\n"
     ]
    }
   ],
   "source": [
    "results_3 = {}\n",
    "redes = [[30, 10, 64, 'relu', 'linear'],\n",
    "         [30, 30, 32, 'linear', 'relu']]\n",
    "\n",
    "for n1, n2, b, a1, a2 in redes:\n",
    "    for drop in [0, 1]:\n",
    "        name = 'na{}_nb{}_b{}_{}_{}_d{}_b'.format(n1, n2, b, a1, a2, drop)\n",
    "        print('Testing ->', name)\n",
    "        # Armo el modelo\n",
    "        test_model = Sequential(name=name)\n",
    "\n",
    "        test_model.add(Dense(n1, activation=a1, input_shape=(x_temp.shape[1],)))\n",
    "        \n",
    "        test_model.add(Dense(n2, activation=a2))\n",
    "        \n",
    "        if drop:\n",
    "            test_model.add(Dropout(rate=0.5))\n",
    "        else:\n",
    "            test_model.add(BatchNormalization())\n",
    "            \n",
    "        test_model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.25)))\n",
    "        # Compilo el modelo\n",
    "        test_model.compile(optimizer=Adam(learning_rate=0.02), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "        auc, metrics, _ = train_model(x_temp, y_temp, test_model, name, b, stopping_patiece=50)\n",
    "        results_3[name] = (auc, metrics)\n",
    "        clear_output(wait=True)\n",
    "                \n",
    "sorted_results_3 = list(reversed(sorted(results_3.items(), key=lambda x: x[1][0])))\n",
    "for i in sorted_results_3:\n",
    "    print(i[0], '->', i[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e256bac3-5304-454a-909f-1d8a7fd49676",
   "metadata": {},
   "source": [
    "Finalmente no se pudieron conseguir mejoras sustanciales agregando capas de Droput o BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f825f34d-74bb-4b77-8f3f-2c5519e508cf",
   "metadata": {},
   "source": [
    "#### Optimizando hypperparametros del optimizador y regularizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcb469e3-9b5d-49e2-8634-73c8e245344d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red1_lr0.02_l20.5_ -> 0.8495475161025089\n",
      "red0_lr0.1_l20.1_ -> 0.8461625165134885\n",
      "red0_lr0.1_l20.25_ -> 0.8453358782084184\n",
      "red1_lr0.05_l20.1_ -> 0.8434988535879414\n",
      "red1_lr0.02_l20.25_ -> 0.8432147286239813\n",
      "red0_lr0.02_l20.05_ -> 0.843123954592139\n",
      "red1_lr0.05_l20.01_ -> 0.8429590729148458\n",
      "red0_lr0.05_l20.1_ -> 0.8429587805234142\n",
      "red1_lr0.02_l20.1_ -> 0.8428239507121829\n",
      "red0_lr0.05_l20.25_ -> 0.8426730011011372\n"
     ]
    }
   ],
   "source": [
    "results_4 = {}\n",
    "redes = [[30, 10, 64, 'relu', 'linear'],\n",
    "         [30, 30, 32, 'linear', 'relu']]\n",
    "\n",
    "for i in [0, 1]:\n",
    "    n1, n2, b, a1, a2 = redes[i]\n",
    "    for lr in [5e-3, 0.01, 0.02, 0.05, 0.1, 0.5]:\n",
    "        for l_2 in [0.01, 0.05, 0.1, 0.25, 0.5]:\n",
    "            name = 'red{}_lr{}_l2{}_'.format(i, lr, l_2)\n",
    "            print('Testing ->', name)\n",
    "            # Armo el modelo\n",
    "            test_model = Sequential(name=name)\n",
    "\n",
    "            test_model.add(Dense(n1, activation=a1, input_shape=(x_temp.shape[1],)))\n",
    "\n",
    "            test_model.add(Dense(n2, activation=a2))\n",
    "\n",
    "            test_model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(l_2)))\n",
    "            # Compilo el modelo\n",
    "            test_model.compile(optimizer=Adam(learning_rate=lr), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "            auc, metrics, _ = train_model(x_temp, y_temp, test_model, name, b, stopping_patiece=50)\n",
    "            results_4[name] = (auc, metrics)\n",
    "            clear_output(wait=True)\n",
    "                \n",
    "sorted_results_4 = list(reversed(sorted(results_4.items(), key=lambda x: x[1][0])))\n",
    "for i in sorted_results_4[:10]:\n",
    "    print(i[0], '->', i[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ce4c3-7715-40d5-89be-31a17e42b034",
   "metadata": {},
   "source": [
    "### Finalmente nos quedamos con le mejor modelo obtenido\n",
    "El mismo cuenta con dos capas ocultas, con 30 neuronas cada una, utilizando el optimizador Adam con un learning rate de 0.05 y regularizacion L2 con l2=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55624b90-ad70-42f6-9940-540b83ca4ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing -> final\n"
     ]
    }
   ],
   "source": [
    "name = 'final'\n",
    "print('Testing ->', name)\n",
    "# Armo el modelo\n",
    "final_model = Sequential(name=name)\n",
    "\n",
    "final_model.add(Dense(30, activation='linear', input_shape=(x_temp.shape[1],)))\n",
    "\n",
    "final_model.add(Dense(30, activation='relu'))\n",
    "\n",
    "final_model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.5)))\n",
    "# Compilo el modelo\n",
    "final_model.compile(optimizer=Adam(learning_rate=0.05), loss=BinaryCrossentropy(), metrics=[AUC(name='auc')])\n",
    "auc, metrics, all_models = train_model(x_temp, y_temp, final_model, name, b, stopping_patiece=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20481374-83a9-4510-a207-cc49ba088061",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "auc_test = []\n",
    "for model in all_models:\n",
    "    final_model.set_weights(model)\n",
    "    metrics = verify_model(final_model, x_train_norm, y_train, x_test_norm, y_test)\n",
    "    auc_test.append(metrics['AUC ROC'][1])\n",
    "    results.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63275fe6-a836-40d9-b854-d5343265c64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACU ROC = 0.9075910931174089\n"
     ]
    }
   ],
   "source": [
    "print('Test ACU ROC = {}'.format(np.mean(auc_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f571635b-ccd5-4601-9799-d5f60016133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models, weights, x):\n",
    "    l = len(weights)\n",
    "    models.set_weights(weights[0])\n",
    "    out = models.predict(x) / l\n",
    "    \n",
    "    for peso in weights[1:]:\n",
    "        models.set_weights(peso)\n",
    "        y = models.predict(x)\n",
    "        out = out + y/l\n",
    "    \n",
    "    return out.copy()\n",
    "        \n",
    "def f2_threshold(model, weigths, x_train, y_train, x_validation, y_validation):\n",
    "    y_train_pred = predict(model, weigths, x_train)\n",
    "    y_valid_pred = predict(model, weigths, x_validation)\n",
    "    th = np.linspace(0, 1, 100)\n",
    "    f2score_v = []\n",
    "    f2score_t = []\n",
    "    max_f = [0, 0]\n",
    "    for t in th:\n",
    "        y_pred_t = (y_train_pred > t).astype(int)\n",
    "        y_pred_v = (y_valid_pred > t).astype(int)\n",
    "        score_t = fbeta_score(y_train, y_pred_t, beta=2)\n",
    "        score_v = fbeta_score(y_validation, y_pred_v, beta=2)\n",
    "        f2score_t.append(score_t)\n",
    "        f2score_v.append(score_v)\n",
    "        if score_v > max_f[0]:\n",
    "            max_f[0] = score_v\n",
    "            max_f[1] = t\n",
    "    \n",
    "    plt.plot(th, f2score_t, label='train')\n",
    "    plt.plot(th, f2score_v, label='valid')\n",
    "    \n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('F2 score')\n",
    "    \n",
    "    plt.axvline(max_f[1], color='black', linestyle='--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1])\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c94075-244b-4523-9002-257ba867f72b",
   "metadata": {},
   "source": [
    "### Eleccion del umbral de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2703072-2923-4b2f-abf4-4254b887ad98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f2_threshold(final_model, all_models,  x_train_norm, y_train, x_valid_norm, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a373d-3c5d-474d-a934-f3f5bbe7d88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
